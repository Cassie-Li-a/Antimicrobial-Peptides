{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for f in os.listdir('.'):\n",
    "    if '.data' in f:\n",
    "        with open(f, 'r') as g:\n",
    "            all_results.append(ast.literal_eval(g.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_to_uM(concentration, unit, sequence):\n",
    "    concentration = concentration.replace(' ', '')\n",
    "    try:\n",
    "        concentration = float(concentration)\n",
    "    except:\n",
    "        return None\n",
    "    if unit == 'uM' or unit == u'\\xb5M' or unit == u'uM)':\n",
    "        return concentration\n",
    "    elif unit == 'ug/ml' or unit == u'\\xb5g/ml' or unit == u'ug/ml)':\n",
    "        try:\n",
    "            molWt = ProteinAnalysis(sequence).molecular_weight()\n",
    "        except ValueError:\n",
    "            return None\n",
    "        return concentration * 1000/molWt\n",
    "    elif unit == 'nmol/g' or unit == 'pmol/mg':\n",
    "        #1g, at density of 1g/mL, is 1mL, so nmol/g is nmol/mL = umol/L = uM yay!\n",
    "        return concentration\n",
    "    else:\n",
    "        # print 'Unit not recognized: ' + unit\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_result_to_rows(sequence, result):\n",
    "    rows = []\n",
    "    if 'bacteria' not in result:\n",
    "        return rows\n",
    "    for bacterium, strain in result['bacteria']:\n",
    "        \n",
    "        rows.append({\n",
    "            'bacterium': bacterium,\n",
    "            'strain': strain,\n",
    "            'sequence': sequence.upper(),\n",
    "            'url_source': result['url_sources'][0],\n",
    "            'value': standardize_to_uM(\n",
    "                result['bacteria'][(bacterium, strain)]['value'],\n",
    "                result['bacteria'][(bacterium, strain)]['unit'],\n",
    "                sequence\n",
    "            ),\n",
    "            'modifications': result['modifications'] if 'modifications' in result else [],\n",
    "            'unit': 'uM'\n",
    "        })\n",
    "        if rows[-1]['value']:\n",
    "            rows[-1]['value'] = np.log10(rows[-1]['value'])\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for result_set in all_results:\n",
    "    for sequence in result_set:\n",
    "        for row in convert_result_to_rows(sequence, result_set[sequence]):\n",
    "            rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_modified(modifications_list):\n",
    "    return len(modifications_list) > 0\n",
    "\n",
    "df['is_modified'] = df.modifications.apply(is_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_non_cterminal_modification(modifications_list):\n",
    "    return any(['C-Term' not in modification for modification in modifications_list])\n",
    "\n",
    "df['has_non_cterminal_modification'] = df.modifications.apply(has_non_cterminal_modification)\n",
    "#df['has_non_cterminal_modification'] = df.groupby(['sequence'])['has_non_cterminal_modification'].transform(max)\n",
    "\n",
    "df['has_cterminal_modification'] = df.is_modified & ~df.has_non_cterminal_modification\n",
    "#df['has_cterminal_modification'] = df.groupby(['sequence'])['has_cterminal_modification'].transform(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean sequences\n",
    "df.sequence = df.sequence.str.strip()\n",
    "df = df.loc[df.sequence != '/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude sequences with modifications\n",
    "\n",
    "# Exclude rows from YADAMP and CAMP for having no modification data\n",
    "\n",
    "#     Unless that sequence is in another DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.has_non_cterminal_modification == False]\n",
    "\n",
    "no_modification_data_sources = ['camp3', 'yadamp']\n",
    "\n",
    "def datasource_has_modifications(cell):\n",
    "    # Everything except CAMP and YADAMP has modification data\n",
    "    return not any([s in cell for s in no_modification_data_sources])\n",
    "\n",
    "df['_datasource_has_modifications'] = df['url_source'].apply(datasource_has_modifications)\n",
    "\n",
    "sequences_containing_modifications = set(df.loc[df._datasource_has_modifications == True, 'sequence'])\n",
    "def sequence_has_modification_data(cell):\n",
    "    # If the sequence is labeled modifictationless in another database it's OK\n",
    "    return cell in sequences_containing_modifications\n",
    "\n",
    "df['_sequence_has_modifications'] = df['sequence'].apply(sequence_has_modification_data)\n",
    "\n",
    "df['modification_verified'] = df['_sequence_has_modifications'] | df['_datasource_has_modifications']\n",
    "\n",
    "df = df.loc[df.modification_verified == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_dict = set([character for sequence in df.sequence for character in sequence])\n",
    "max_sequence_length = int(df.sequence.str.len().describe(percentiles=[0.95])['95%'])\n",
    "character_to_index = {\n",
    "    character: i\n",
    "    for i, character in enumerate(character_dict)\n",
    "}\n",
    "\n",
    "# max_sequence_length = 3\n",
    "\n",
    "\n",
    "def sequence_to_vector(sequence, cterminal_amidation):\n",
    "    default = np.zeros([max_sequence_length, len(character_to_index) + 1])\n",
    "    for i, character in enumerate(sequence[:max_sequence_length]):\n",
    "        default[i][character_to_index[character]] = 1\n",
    "        default[i][-1] = cterminal_amidation\n",
    "    return default\n",
    "\n",
    "\n",
    "def row_to_vector(row):\n",
    "    sequence = row['sequence']\n",
    "    cterminal_amidation = row['has_cterminal_modification']\n",
    "    default = np.zeros([max_sequence_length, len(character_to_index) + 1])\n",
    "\n",
    "    for i, character in enumerate(sequence[:max_sequence_length]):\n",
    "        default[i][character_to_index[character]] = 1\n",
    "        default[i][-1] = cterminal_amidation\n",
    "\n",
    "    return default\n",
    "\n",
    "def bacterium_to_sample_weight(bacterium, intended_bacterium='E. coli'):\n",
    "    if intended_bacterium in bacterium:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "staph = df.loc[df.bacterium.str.contains('S. aureus')].groupby('sequence')['value'].mean().dropna()\n",
    "ecoli = df.loc[df.bacterium.str.contains('E. coli')].groupby('sequence')['value'].mean().dropna()\n",
    "pseudomonas = df.loc[df.bacterium.str.contains('P. aeruginosa')].groupby('sequence')['value'].mean().dropna()\n",
    "streptococcus = df.loc[df.bacterium.str.contains('S. mutans')].groupby('sequence')['value'].mean().dropna()\n",
    "bacillus = df.loc[df.bacterium.str.contains('B. subtilis')].groupby('sequence')['value'].mean().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_bacteria = pd.concat([ecoli, pseudomonas, streptococcus, staph, bacillus], axis=1).reset_index()\n",
    "many_bacteria.columns = ['index', 'ecoli', 'pseudomonas', 'streptococcus', 'staph', 'bacillus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoli_pseudomonas = many_bacteria.dropna(subset=('ecoli', 'pseudomonas'))\n",
    "x = np.array(ecoli_pseudomonas['pseudomonas']).reshape(-1, 1)\n",
    "y = np.array(ecoli_pseudomonas['ecoli']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Vector shape:', (4508, 46, 24))\n"
     ]
    }
   ],
   "source": [
    "bacteria_name = 'E. coli'\n",
    "ecoli_df = df.loc[(df.bacterium.str.contains(bacteria_name))].groupby(['sequence', 'bacterium'])\n",
    "ecoli_df = ecoli_df.mean().reset_index().dropna()\n",
    "\n",
    "cterminal_amidation = np.array(ecoli_df.has_cterminal_modification)\n",
    "\n",
    "# vectors = ecoli_df.head(2).apply(sequence_to_vector, axis=1)\n",
    "vectors = []\n",
    "for row in ecoli_df.iterrows():\n",
    "    vectors.append(row_to_vector(row[1]))\n",
    "\n",
    "vectors = np.array(vectors)\n",
    "print(\"Vector shape:\", vectors.shape)\n",
    "\n",
    "labels = np.array(ecoli_df.value)\n",
    "sample_weights = np.array([1] * len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Vector shape:', (2493, 46, 24))\n"
     ]
    }
   ],
   "source": [
    "bacteria_name = 'P. aeruginosa'\n",
    "# ecoli_df = df.loc[(df.bacterium.str.contains('E. coli')) | (df.bacterium.str.contains('P. aeruginosa'))].groupby(['sequence', 'bacterium'])\n",
    "pa_df = df.loc[(df.bacterium.str.contains(bacteria_name))].groupby(['sequence', 'bacterium'])\n",
    "pa_df = pa_df.mean().reset_index().dropna()\n",
    "\n",
    "pa_cterminal_amidation = np.array(pa_df.has_cterminal_modification)\n",
    "\n",
    "pa_vectors = []\n",
    "for row in pa_df.iterrows():\n",
    "    pa_vectors.append(row_to_vector(row[1]))\n",
    "\n",
    "pa_vectors = np.array(pa_vectors)\n",
    "print(\"Vector shape:\", pa_vectors.shape)\n",
    "\n",
    "pa_labels = np.array(pa_df.value.apply(model.predict))  # Interpolate using the linear model\n",
    "pa_sample_weights = np.array([0.5] * len(pa_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60182344038256\n"
     ]
    }
   ],
   "source": [
    "average = np.mean(labels)\n",
    "squared_errors = sum([(label - average) ** 2 for label in labels])\n",
    "baseline_error = squared_errors/len(labels)\n",
    "print(baseline_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zswitten/.pyenv/versions/2.7.12/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Dropout, LSTM, Conv2D, Conv1D, MaxPooling1D, MaxPooling2D, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(LSTM(\n",
    "        128,\n",
    "        input_shape=(max_sequence_length, len(character_to_index) + 1),\n",
    "    ))\n",
    "    \"\"\"model.add(Dense(\n",
    "        max_sequence_length * len(character_to_index),\n",
    "        input_dim = max_sequence_length * len(character_to_index),\n",
    "        kernel_initializer='normal',\n",
    "        activation='relu'\n",
    "    ))\"\"\"\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, kernel_initializer='normal'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Conv1D(\n",
    "        64,\n",
    "        kernel_size = 5,\n",
    "        strides = 1,\n",
    "        activation = 'relu',\n",
    "        input_shape = (max_sequence_length, len(character_to_index) + 1)\n",
    "    ))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(64, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    #model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zswitten/.pyenv/versions/2.7.12/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/zswitten/.pyenv/versions/2.7.12/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = int(0.9 * len(labels))\n",
    "train_x = np.concatenate((vectors[:cutoff], pa_vectors))\n",
    "train_y = np.concatenate((labels[:cutoff], pa_labels))\n",
    "train_sample_weights = np.concatenate((sample_weights[:cutoff], pa_sample_weights))\n",
    "test_x = vectors[cutoff:]\n",
    "test_y = labels[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.6293\n",
      "Epoch 2/100\n",
      "6550/6550 [==============================] - 6s 983us/step - loss: 0.4891\n",
      "Epoch 3/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.4405\n",
      "Epoch 4/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.4218\n",
      "Epoch 5/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.4231\n",
      "Epoch 6/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.4181\n",
      "Epoch 7/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.4042\n",
      "Epoch 8/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.3979\n",
      "Epoch 9/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.3962\n",
      "Epoch 10/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.3939\n",
      "Epoch 11/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.3887\n",
      "Epoch 12/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.3789\n",
      "Epoch 13/100\n",
      "6550/6550 [==============================] - 6s 987us/step - loss: 0.3781\n",
      "Epoch 14/100\n",
      "6550/6550 [==============================] - 6s 991us/step - loss: 0.3686\n",
      "Epoch 15/100\n",
      "6550/6550 [==============================] - 6s 969us/step - loss: 0.3612\n",
      "Epoch 16/100\n",
      "6550/6550 [==============================] - 6s 971us/step - loss: 0.3582\n",
      "Epoch 17/100\n",
      "6550/6550 [==============================] - 6s 975us/step - loss: 0.3516\n",
      "Epoch 18/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.3538\n",
      "Epoch 19/100\n",
      "6550/6550 [==============================] - 6s 980us/step - loss: 0.3401\n",
      "Epoch 20/100\n",
      "6550/6550 [==============================] - 6s 974us/step - loss: 0.3398\n",
      "Epoch 21/100\n",
      "6550/6550 [==============================] - 6s 980us/step - loss: 0.3367\n",
      "Epoch 22/100\n",
      "6550/6550 [==============================] - 6s 989us/step - loss: 0.3240\n",
      "Epoch 23/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.3175\n",
      "Epoch 24/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.3109\n",
      "Epoch 25/100\n",
      "6550/6550 [==============================] - 6s 965us/step - loss: 0.3127\n",
      "Epoch 26/100\n",
      "6550/6550 [==============================] - 6s 944us/step - loss: 0.3046\n",
      "Epoch 27/100\n",
      "6550/6550 [==============================] - 6s 978us/step - loss: 0.2950\n",
      "Epoch 28/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.2931\n",
      "Epoch 29/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.2907\n",
      "Epoch 30/100\n",
      "6550/6550 [==============================] - 7s 996us/step - loss: 0.2801\n",
      "Epoch 31/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.2793\n",
      "Epoch 32/100\n",
      "6550/6550 [==============================] - 6s 966us/step - loss: 0.2711\n",
      "Epoch 33/100\n",
      "6550/6550 [==============================] - 6s 972us/step - loss: 0.2620\n",
      "Epoch 34/100\n",
      "6550/6550 [==============================] - 6s 970us/step - loss: 0.2590\n",
      "Epoch 35/100\n",
      "6550/6550 [==============================] - 6s 959us/step - loss: 0.2476\n",
      "Epoch 36/100\n",
      "6550/6550 [==============================] - 6s 967us/step - loss: 0.2434\n",
      "Epoch 37/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.2384\n",
      "Epoch 38/100\n",
      "6550/6550 [==============================] - 6s 952us/step - loss: 0.2316\n",
      "Epoch 39/100\n",
      "6550/6550 [==============================] - 7s 994us/step - loss: 0.2246\n",
      "Epoch 40/100\n",
      "6550/6550 [==============================] - 7s 998us/step - loss: 0.2197\n",
      "Epoch 41/100\n",
      "6550/6550 [==============================] - 6s 981us/step - loss: 0.2204\n",
      "Epoch 42/100\n",
      "6550/6550 [==============================] - 6s 982us/step - loss: 0.2082\n",
      "Epoch 43/100\n",
      "6550/6550 [==============================] - 6s 979us/step - loss: 0.2049\n",
      "Epoch 44/100\n",
      "6550/6550 [==============================] - 6s 984us/step - loss: 0.1977\n",
      "Epoch 45/100\n",
      "6550/6550 [==============================] - 6s 992us/step - loss: 0.1942\n",
      "Epoch 46/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1862\n",
      "Epoch 47/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1857\n",
      "Epoch 48/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1803\n",
      "Epoch 49/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1742\n",
      "Epoch 50/100\n",
      "6550/6550 [==============================] - 6s 978us/step - loss: 0.1692\n",
      "Epoch 51/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1665\n",
      "Epoch 52/100\n",
      "6550/6550 [==============================] - 6s 988us/step - loss: 0.1625\n",
      "Epoch 53/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1564\n",
      "Epoch 54/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1597\n",
      "Epoch 55/100\n",
      "6550/6550 [==============================] - 6s 985us/step - loss: 0.1548\n",
      "Epoch 56/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1489\n",
      "Epoch 57/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1462\n",
      "Epoch 58/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1426\n",
      "Epoch 59/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1403\n",
      "Epoch 60/100\n",
      "6550/6550 [==============================] - 7s 999us/step - loss: 0.1343\n",
      "Epoch 61/100\n",
      "6550/6550 [==============================] - 6s 983us/step - loss: 0.1384\n",
      "Epoch 62/100\n",
      "6550/6550 [==============================] - 7s 996us/step - loss: 0.1321\n",
      "Epoch 63/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1315\n",
      "Epoch 64/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1331\n",
      "Epoch 65/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1234\n",
      "Epoch 66/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1198\n",
      "Epoch 67/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1192\n",
      "Epoch 68/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1194\n",
      "Epoch 69/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1163\n",
      "Epoch 70/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1149\n",
      "Epoch 71/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1121\n",
      "Epoch 72/100\n",
      "6550/6550 [==============================] - 7s 996us/step - loss: 0.1087\n",
      "Epoch 73/100\n",
      "6550/6550 [==============================] - 6s 957us/step - loss: 0.1152\n",
      "Epoch 74/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1090\n",
      "Epoch 75/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1069\n",
      "Epoch 76/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1029\n",
      "Epoch 77/100\n",
      "6550/6550 [==============================] - 7s 996us/step - loss: 0.1062\n",
      "Epoch 78/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1076\n",
      "Epoch 79/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.1013\n",
      "Epoch 80/100\n",
      "6550/6550 [==============================] - 7s 998us/step - loss: 0.0988\n",
      "Epoch 81/100\n",
      "6550/6550 [==============================] - 6s 986us/step - loss: 0.0971\n",
      "Epoch 82/100\n",
      "6550/6550 [==============================] - 6s 986us/step - loss: 0.0958\n",
      "Epoch 83/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0968\n",
      "Epoch 84/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0978\n",
      "Epoch 85/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0947\n",
      "Epoch 86/100\n",
      "6550/6550 [==============================] - 6s 973us/step - loss: 0.0932\n",
      "Epoch 87/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0915\n",
      "Epoch 88/100\n",
      "6550/6550 [==============================] - 7s 994us/step - loss: 0.0903\n",
      "Epoch 89/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0898\n",
      "Epoch 90/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0891\n",
      "Epoch 91/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0891\n",
      "Epoch 92/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0933\n",
      "Epoch 93/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0869\n",
      "Epoch 94/100\n",
      "6550/6550 [==============================] - 6s 987us/step - loss: 0.0854\n",
      "Epoch 95/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0848\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6550/6550 [==============================] - 6s 985us/step - loss: 0.0844\n",
      "Epoch 97/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0853\n",
      "Epoch 98/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0842\n",
      "Epoch 99/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0828\n",
      "Epoch 100/100\n",
      "6550/6550 [==============================] - 7s 1ms/step - loss: 0.0804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117a8ac10>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, sample_weight=[], batch_size=40, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6300/6300 [==============================] - 9s 1ms/step - loss: 0.6312\n",
      "Epoch 2/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.5538\n",
      "Epoch 3/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.4889\n",
      "Epoch 4/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.4335\n",
      "Epoch 5/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.4308\n",
      "Epoch 6/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.4298\n",
      "Epoch 7/100\n",
      "6300/6300 [==============================] - 6s 1ms/step - loss: 0.4111\n",
      "Epoch 8/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.4157\n",
      "Epoch 9/100\n",
      "6300/6300 [==============================] - 6s 989us/step - loss: 0.4039\n",
      "Epoch 10/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.3983\n",
      "Epoch 11/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.3947\n",
      "Epoch 12/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.3915\n",
      "Epoch 13/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.3905\n",
      "Epoch 14/100\n",
      "6300/6300 [==============================] - 6s 953us/step - loss: 0.3868\n",
      "Epoch 15/100\n",
      "6300/6300 [==============================] - 6s 1ms/step - loss: 0.3786\n",
      "Epoch 16/100\n",
      "6300/6300 [==============================] - 6s 992us/step - loss: 0.3675\n",
      "Epoch 17/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.3600\n",
      "Epoch 18/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.3635\n",
      "Epoch 19/100\n",
      "6300/6300 [==============================] - 6s 977us/step - loss: 0.3561\n",
      "Epoch 20/100\n",
      "6300/6300 [==============================] - 6s 962us/step - loss: 0.3509\n",
      "Epoch 21/100\n",
      "6300/6300 [==============================] - 6s 959us/step - loss: 0.3424\n",
      "Epoch 22/100\n",
      "6300/6300 [==============================] - 6s 912us/step - loss: 0.3400\n",
      "Epoch 23/100\n",
      "6300/6300 [==============================] - 6s 932us/step - loss: 0.3335\n",
      "Epoch 24/100\n",
      "6300/6300 [==============================] - 6s 951us/step - loss: 0.3211\n",
      "Epoch 25/100\n",
      "6300/6300 [==============================] - 6s 988us/step - loss: 0.3212\n",
      "Epoch 26/100\n",
      "6300/6300 [==============================] - 6s 943us/step - loss: 0.3137\n",
      "Epoch 27/100\n",
      "6300/6300 [==============================] - 6s 982us/step - loss: 0.3063\n",
      "Epoch 28/100\n",
      "6300/6300 [==============================] - 6s 977us/step - loss: 0.3042\n",
      "Epoch 29/100\n",
      "6300/6300 [==============================] - 6s 957us/step - loss: 0.2877\n",
      "Epoch 30/100\n",
      "6300/6300 [==============================] - 6s 978us/step - loss: 0.2873\n",
      "Epoch 31/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.2789\n",
      "Epoch 32/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.2692\n",
      "Epoch 33/100\n",
      "6300/6300 [==============================] - 6s 968us/step - loss: 0.2677\n",
      "Epoch 34/100\n",
      "6300/6300 [==============================] - 6s 954us/step - loss: 0.2631\n",
      "Epoch 35/100\n",
      "6300/6300 [==============================] - 6s 939us/step - loss: 0.2588\n",
      "Epoch 36/100\n",
      "6300/6300 [==============================] - 6s 994us/step - loss: 0.2551\n",
      "Epoch 37/100\n",
      "6300/6300 [==============================] - 6s 963us/step - loss: 0.2475\n",
      "Epoch 38/100\n",
      "6300/6300 [==============================] - 6s 986us/step - loss: 0.2410\n",
      "Epoch 39/100\n",
      "6300/6300 [==============================] - 6s 985us/step - loss: 0.2346\n",
      "Epoch 40/100\n",
      "6300/6300 [==============================] - 6s 982us/step - loss: 0.2275\n",
      "Epoch 41/100\n",
      "6300/6300 [==============================] - 6s 991us/step - loss: 0.2198\n",
      "Epoch 42/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.2200\n",
      "Epoch 43/100\n",
      "6300/6300 [==============================] - 6s 969us/step - loss: 0.2173\n",
      "Epoch 44/100\n",
      "6300/6300 [==============================] - 6s 966us/step - loss: 0.2117\n",
      "Epoch 45/100\n",
      "6300/6300 [==============================] - 6s 973us/step - loss: 0.2059\n",
      "Epoch 46/100\n",
      "6300/6300 [==============================] - 6s 965us/step - loss: 0.1995\n",
      "Epoch 47/100\n",
      "6300/6300 [==============================] - 6s 926us/step - loss: 0.1947\n",
      "Epoch 48/100\n",
      "6300/6300 [==============================] - 6s 997us/step - loss: 0.1934\n",
      "Epoch 49/100\n",
      "6300/6300 [==============================] - 6s 969us/step - loss: 0.1866\n",
      "Epoch 50/100\n",
      "6300/6300 [==============================] - 6s 953us/step - loss: 0.1885\n",
      "Epoch 51/100\n",
      "6300/6300 [==============================] - 6s 976us/step - loss: 0.1879\n",
      "Epoch 52/100\n",
      "6300/6300 [==============================] - 6s 953us/step - loss: 0.1772\n",
      "Epoch 53/100\n",
      "6300/6300 [==============================] - 6s 955us/step - loss: 0.1756\n",
      "Epoch 54/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.1710\n",
      "Epoch 55/100\n",
      "6300/6300 [==============================] - 6s 1ms/step - loss: 0.1676\n",
      "Epoch 56/100\n",
      "6300/6300 [==============================] - 6s 1ms/step - loss: 0.1653\n",
      "Epoch 57/100\n",
      "6300/6300 [==============================] - 6s 983us/step - loss: 0.1634\n",
      "Epoch 58/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.1609\n",
      "Epoch 59/100\n",
      "6300/6300 [==============================] - 6s 969us/step - loss: 0.1558\n",
      "Epoch 60/100\n",
      "6300/6300 [==============================] - 6s 970us/step - loss: 0.1527\n",
      "Epoch 61/100\n",
      "6300/6300 [==============================] - 6s 962us/step - loss: 0.1525\n",
      "Epoch 62/100\n",
      "6300/6300 [==============================] - 6s 962us/step - loss: 0.1496\n",
      "Epoch 63/100\n",
      "6300/6300 [==============================] - 6s 966us/step - loss: 0.1497\n",
      "Epoch 64/100\n",
      "6300/6300 [==============================] - 6s 960us/step - loss: 0.1438\n",
      "Epoch 65/100\n",
      "6300/6300 [==============================] - 6s 949us/step - loss: 0.1429\n",
      "Epoch 66/100\n",
      "6300/6300 [==============================] - 6s 945us/step - loss: 0.1401\n",
      "Epoch 67/100\n",
      "6300/6300 [==============================] - 6s 967us/step - loss: 0.1410\n",
      "Epoch 68/100\n",
      "6300/6300 [==============================] - 6s 958us/step - loss: 0.1361\n",
      "Epoch 69/100\n",
      "6300/6300 [==============================] - 6s 977us/step - loss: 0.1340\n",
      "Epoch 70/100\n",
      "6300/6300 [==============================] - 6s 1ms/step - loss: 0.1320\n",
      "Epoch 71/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.1304\n",
      "Epoch 72/100\n",
      "6300/6300 [==============================] - 6s 981us/step - loss: 0.1299\n",
      "Epoch 73/100\n",
      "6300/6300 [==============================] - 7s 1ms/step - loss: 0.1277\n",
      "Epoch 74/100\n",
      "6300/6300 [==============================] - 6s 1ms/step - loss: 0.1252\n",
      "Epoch 75/100\n",
      "6300/6300 [==============================] - 6s 978us/step - loss: 0.1321\n",
      "Epoch 76/100\n",
      "6300/6300 [==============================] - 6s 946us/step - loss: 0.1259\n",
      "Epoch 77/100\n",
      "6300/6300 [==============================] - 6s 939us/step - loss: 0.1189\n",
      "Epoch 78/100\n",
      "6300/6300 [==============================] - 6s 973us/step - loss: 0.1178\n",
      "Epoch 79/100\n",
      "6300/6300 [==============================] - 6s 941us/step - loss: 0.1200\n",
      "Epoch 80/100\n",
      "6300/6300 [==============================] - 6s 975us/step - loss: 0.1175\n",
      "Epoch 81/100\n",
      "6300/6300 [==============================] - 6s 963us/step - loss: 0.1146\n",
      "Epoch 82/100\n",
      "6300/6300 [==============================] - 6s 952us/step - loss: 0.1138\n",
      "Epoch 83/100\n",
      "6300/6300 [==============================] - 6s 1ms/step - loss: 0.1130\n",
      "Epoch 84/100\n",
      "6300/6300 [==============================] - 6s 939us/step - loss: 0.1116\n",
      "Epoch 85/100\n",
      "6300/6300 [==============================] - 6s 983us/step - loss: 0.1108\n",
      "Epoch 86/100\n",
      "6300/6300 [==============================] - 6s 963us/step - loss: 0.1118\n",
      "Epoch 87/100\n",
      "6300/6300 [==============================] - 6s 952us/step - loss: 0.1054\n",
      "Epoch 88/100\n",
      "6300/6300 [==============================] - 6s 981us/step - loss: 0.1072\n",
      "Epoch 89/100\n",
      "6300/6300 [==============================] - 6s 974us/step - loss: 0.1046\n",
      "Epoch 90/100\n",
      "6300/6300 [==============================] - 6s 962us/step - loss: 0.1059\n",
      "Epoch 91/100\n",
      "6300/6300 [==============================] - 6s 991us/step - loss: 0.1013\n",
      "Epoch 92/100\n",
      "6300/6300 [==============================] - 6s 942us/step - loss: 0.1012\n",
      "Epoch 93/100\n",
      "6300/6300 [==============================] - 6s 940us/step - loss: 0.1032\n",
      "Epoch 94/100\n",
      "6300/6300 [==============================] - 6s 970us/step - loss: 0.0985\n",
      "Epoch 95/100\n",
      "6300/6300 [==============================] - 6s 959us/step - loss: 0.0976\n",
      "Epoch 96/100\n",
      "6300/6300 [==============================] - 6s 968us/step - loss: 0.0973\n",
      "Epoch 97/100\n",
      "6300/6300 [==============================] - 6s 979us/step - loss: 0.0963\n",
      "Epoch 98/100\n",
      "6300/6300 [==============================] - 6s 1ms/step - loss: 0.0975\n",
      "Epoch 99/100\n",
      "6300/6300 [==============================] - 6s 962us/step - loss: 0.0955\n",
      "Epoch 100/100\n",
      "6300/6300 [==============================] - 6s 967us/step - loss: 0.0949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1890d1d50>"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=40, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zswitten/.pyenv/versions/2.7.12/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "WARNING:tensorflow:From /Users/zswitten/.pyenv/versions/2.7.12/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/200\n",
      "6550/6550 [==============================] - 1s 176us/step - loss: 0.5293\n",
      "Epoch 2/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.3844\n",
      "Epoch 3/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.3396\n",
      "Epoch 4/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.3099\n",
      "Epoch 5/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.2880\n",
      "Epoch 6/200\n",
      "6550/6550 [==============================] - 1s 149us/step - loss: 0.2616\n",
      "Epoch 7/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.2365\n",
      "Epoch 8/200\n",
      "6550/6550 [==============================] - 1s 139us/step - loss: 0.2320\n",
      "Epoch 9/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.2174\n",
      "Epoch 10/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.2049\n",
      "Epoch 11/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.1986\n",
      "Epoch 12/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.1874\n",
      "Epoch 13/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.1827\n",
      "Epoch 14/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.1740\n",
      "Epoch 15/200\n",
      "6550/6550 [==============================] - 1s 143us/step - loss: 0.1718\n",
      "Epoch 16/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.1662\n",
      "Epoch 17/200\n",
      "6550/6550 [==============================] - 1s 140us/step - loss: 0.1665\n",
      "Epoch 18/200\n",
      "6550/6550 [==============================] - 1s 127us/step - loss: 0.1638\n",
      "Epoch 19/200\n",
      "6550/6550 [==============================] - 1s 129us/step - loss: 0.1543\n",
      "Epoch 20/200\n",
      "6550/6550 [==============================] - 1s 127us/step - loss: 0.1516\n",
      "Epoch 21/200\n",
      "6550/6550 [==============================] - 1s 127us/step - loss: 0.1543\n",
      "Epoch 22/200\n",
      "6550/6550 [==============================] - 1s 126us/step - loss: 0.1515\n",
      "Epoch 23/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.1457\n",
      "Epoch 24/200\n",
      "6550/6550 [==============================] - 1s 125us/step - loss: 0.1380\n",
      "Epoch 25/200\n",
      "6550/6550 [==============================] - 1s 127us/step - loss: 0.1391\n",
      "Epoch 26/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.1403\n",
      "Epoch 27/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.1349\n",
      "Epoch 28/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.1332\n",
      "Epoch 29/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.1335\n",
      "Epoch 30/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.1316\n",
      "Epoch 31/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.1328\n",
      "Epoch 32/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.1309\n",
      "Epoch 33/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.1287\n",
      "Epoch 34/200\n",
      "6550/6550 [==============================] - 1s 145us/step - loss: 0.1276\n",
      "Epoch 35/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.1267\n",
      "Epoch 36/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.1241\n",
      "Epoch 37/200\n",
      "6550/6550 [==============================] - 1s 155us/step - loss: 0.1222\n",
      "Epoch 38/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.1250\n",
      "Epoch 39/200\n",
      "6550/6550 [==============================] - 1s 146us/step - loss: 0.1234\n",
      "Epoch 40/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.1223\n",
      "Epoch 41/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.1223\n",
      "Epoch 42/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.1192\n",
      "Epoch 43/200\n",
      "6550/6550 [==============================] - 1s 145us/step - loss: 0.1166\n",
      "Epoch 44/200\n",
      "6550/6550 [==============================] - 1s 156us/step - loss: 0.1185\n",
      "Epoch 45/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.1167\n",
      "Epoch 46/200\n",
      "6550/6550 [==============================] - 1s 126us/step - loss: 0.1206\n",
      "Epoch 47/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.1146\n",
      "Epoch 48/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.1153\n",
      "Epoch 49/200\n",
      "6550/6550 [==============================] - 1s 143us/step - loss: 0.1138\n",
      "Epoch 50/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.1115\n",
      "Epoch 51/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.1123\n",
      "Epoch 52/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.1160\n",
      "Epoch 53/200\n",
      "6550/6550 [==============================] - 1s 125us/step - loss: 0.1118\n",
      "Epoch 54/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.1130\n",
      "Epoch 55/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.1114\n",
      "Epoch 56/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.1103\n",
      "Epoch 57/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.1092\n",
      "Epoch 58/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.1069\n",
      "Epoch 59/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.1087\n",
      "Epoch 60/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.1084\n",
      "Epoch 61/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.1035\n",
      "Epoch 62/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.1077\n",
      "Epoch 63/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.1065\n",
      "Epoch 64/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.1066\n",
      "Epoch 65/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.1069\n",
      "Epoch 66/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.1040\n",
      "Epoch 67/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.1032\n",
      "Epoch 68/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.1038\n",
      "Epoch 69/200\n",
      "6550/6550 [==============================] - 1s 126us/step - loss: 0.1034\n",
      "Epoch 70/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.1017\n",
      "Epoch 71/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.1027\n",
      "Epoch 72/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.1048\n",
      "Epoch 73/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.1025\n",
      "Epoch 74/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.1014\n",
      "Epoch 75/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.1029\n",
      "Epoch 76/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.1000\n",
      "Epoch 77/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.1009\n",
      "Epoch 78/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.1031\n",
      "Epoch 79/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.0995\n",
      "Epoch 80/200\n",
      "6550/6550 [==============================] - 1s 126us/step - loss: 0.0987\n",
      "Epoch 81/200\n",
      "6550/6550 [==============================] - 1s 127us/step - loss: 0.0971\n",
      "Epoch 82/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0957\n",
      "Epoch 83/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0974\n",
      "Epoch 84/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0967\n",
      "Epoch 85/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0980\n",
      "Epoch 86/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.0977\n",
      "Epoch 87/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0942\n",
      "Epoch 88/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.0975\n",
      "Epoch 89/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0958\n",
      "Epoch 90/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0957\n",
      "Epoch 91/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0966\n",
      "Epoch 92/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0962\n",
      "Epoch 93/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0909\n",
      "Epoch 94/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0922\n",
      "Epoch 95/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.0927\n",
      "Epoch 96/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0916\n",
      "Epoch 97/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.0927\n",
      "Epoch 98/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0919\n",
      "Epoch 99/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.0913\n",
      "Epoch 100/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0915\n",
      "Epoch 101/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.0923\n",
      "Epoch 102/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.0940\n",
      "Epoch 103/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.0919\n",
      "Epoch 104/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0917\n",
      "Epoch 105/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0921\n",
      "Epoch 106/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0907\n",
      "Epoch 107/200\n",
      "6550/6550 [==============================] - 1s 125us/step - loss: 0.0928\n",
      "Epoch 108/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.0926\n",
      "Epoch 109/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0892\n",
      "Epoch 110/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0892\n",
      "Epoch 111/200\n",
      "6550/6550 [==============================] - 1s 129us/step - loss: 0.0908\n",
      "Epoch 112/200\n",
      "6550/6550 [==============================] - 1s 129us/step - loss: 0.0902\n",
      "Epoch 113/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0890\n",
      "Epoch 114/200\n",
      "6550/6550 [==============================] - 1s 120us/step - loss: 0.0878\n",
      "Epoch 115/200\n",
      "6550/6550 [==============================] - 1s 120us/step - loss: 0.0908\n",
      "Epoch 116/200\n",
      "6550/6550 [==============================] - 1s 120us/step - loss: 0.0916\n",
      "Epoch 117/200\n",
      "6550/6550 [==============================] - 1s 119us/step - loss: 0.0900\n",
      "Epoch 118/200\n",
      "6550/6550 [==============================] - 1s 120us/step - loss: 0.0916\n",
      "Epoch 119/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0895\n",
      "Epoch 120/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0874\n",
      "Epoch 121/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0876\n",
      "Epoch 122/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0908\n",
      "Epoch 123/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0878\n",
      "Epoch 124/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.0902\n",
      "Epoch 125/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0887\n",
      "Epoch 126/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0871\n",
      "Epoch 127/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.0862\n",
      "Epoch 128/200\n",
      "6550/6550 [==============================] - 1s 125us/step - loss: 0.0863\n",
      "Epoch 129/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.0857\n",
      "Epoch 130/200\n",
      "6550/6550 [==============================] - 1s 125us/step - loss: 0.0856\n",
      "Epoch 131/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.0878\n",
      "Epoch 132/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0875\n",
      "Epoch 133/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0863\n",
      "Epoch 134/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0871\n",
      "Epoch 135/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0882\n",
      "Epoch 136/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0829\n",
      "Epoch 137/200\n",
      "6550/6550 [==============================] - 1s 125us/step - loss: 0.0877\n",
      "Epoch 138/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0872\n",
      "Epoch 139/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0856\n",
      "Epoch 140/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0864\n",
      "Epoch 141/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.0843\n",
      "Epoch 142/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0853\n",
      "Epoch 143/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.0850\n",
      "Epoch 144/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0849\n",
      "Epoch 145/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0879\n",
      "Epoch 146/200\n",
      "6550/6550 [==============================] - 1s 125us/step - loss: 0.0852\n",
      "Epoch 147/200\n",
      "6550/6550 [==============================] - 1s 125us/step - loss: 0.0842\n",
      "Epoch 148/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.0865\n",
      "Epoch 149/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0839\n",
      "Epoch 150/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0837\n",
      "Epoch 151/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0832\n",
      "Epoch 152/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0825\n",
      "Epoch 153/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0824\n",
      "Epoch 154/200\n",
      "6550/6550 [==============================] - 1s 121us/step - loss: 0.0823\n",
      "Epoch 155/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0832\n",
      "Epoch 156/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.0820\n",
      "Epoch 157/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.0818\n",
      "Epoch 158/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.0839\n",
      "Epoch 159/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0833\n",
      "Epoch 160/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0831\n",
      "Epoch 161/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0834\n",
      "Epoch 162/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0833\n",
      "Epoch 163/200\n",
      "6550/6550 [==============================] - 1s 124us/step - loss: 0.0839\n",
      "Epoch 164/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0819\n",
      "Epoch 165/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0816\n",
      "Epoch 166/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0822\n",
      "Epoch 167/200\n",
      "6550/6550 [==============================] - 1s 122us/step - loss: 0.0806\n",
      "Epoch 168/200\n",
      "6550/6550 [==============================] - 1s 123us/step - loss: 0.0844\n",
      "Epoch 169/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.0810\n",
      "Epoch 170/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0800\n",
      "Epoch 171/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0809\n",
      "Epoch 172/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0806\n",
      "Epoch 173/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.0807\n",
      "Epoch 174/200\n",
      "6550/6550 [==============================] - 1s 141us/step - loss: 0.0800\n",
      "Epoch 175/200\n",
      "6550/6550 [==============================] - 1s 139us/step - loss: 0.0817\n",
      "Epoch 176/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0807\n",
      "Epoch 177/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0834\n",
      "Epoch 178/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.0809\n",
      "Epoch 179/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.0812\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6550/6550 [==============================] - 1s 128us/step - loss: 0.0815\n",
      "Epoch 181/200\n",
      "6550/6550 [==============================] - 1s 126us/step - loss: 0.0792\n",
      "Epoch 182/200\n",
      "6550/6550 [==============================] - 1s 129us/step - loss: 0.0798\n",
      "Epoch 183/200\n",
      "6550/6550 [==============================] - 1s 126us/step - loss: 0.0797\n",
      "Epoch 184/200\n",
      "6550/6550 [==============================] - 1s 127us/step - loss: 0.0819\n",
      "Epoch 185/200\n",
      "6550/6550 [==============================] - 1s 128us/step - loss: 0.0813\n",
      "Epoch 186/200\n",
      "6550/6550 [==============================] - 1s 127us/step - loss: 0.0800\n",
      "Epoch 187/200\n",
      "6550/6550 [==============================] - 1s 127us/step - loss: 0.0778\n",
      "Epoch 188/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.0802\n",
      "Epoch 189/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0808\n",
      "Epoch 190/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.0789\n",
      "Epoch 191/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.0808\n",
      "Epoch 192/200\n",
      "6550/6550 [==============================] - 1s 129us/step - loss: 0.0780\n",
      "Epoch 193/200\n",
      "6550/6550 [==============================] - 1s 129us/step - loss: 0.0788\n",
      "Epoch 194/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0797\n",
      "Epoch 195/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.0773\n",
      "Epoch 196/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0781\n",
      "Epoch 197/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0794\n",
      "Epoch 198/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0803\n",
      "Epoch 199/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0799\n",
      "Epoch 200/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x115c26ad0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convmodel = conv_model()\n",
    "convmodel.fit(train_x, train_y, batch_size=40, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6550/6550 [==============================] - 1s 185us/step - loss: 0.5157\n",
      "Epoch 2/200\n",
      "6550/6550 [==============================] - 1s 127us/step - loss: 0.3797\n",
      "Epoch 3/200\n",
      "6550/6550 [==============================] - 1s 127us/step - loss: 0.3350\n",
      "Epoch 4/200\n",
      "6550/6550 [==============================] - 1s 127us/step - loss: 0.3011\n",
      "Epoch 5/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.2731\n",
      "Epoch 6/200\n",
      "6550/6550 [==============================] - 1s 129us/step - loss: 0.2536\n",
      "Epoch 7/200\n",
      "6550/6550 [==============================] - 1s 128us/step - loss: 0.2384\n",
      "Epoch 8/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.2203\n",
      "Epoch 9/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.2119\n",
      "Epoch 10/200\n",
      "6550/6550 [==============================] - 1s 127us/step - loss: 0.1989\n",
      "Epoch 11/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.1924\n",
      "Epoch 12/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.1855\n",
      "Epoch 13/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.1834\n",
      "Epoch 14/200\n",
      "6550/6550 [==============================] - 1s 129us/step - loss: 0.1805\n",
      "Epoch 15/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.1661\n",
      "Epoch 16/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.1615\n",
      "Epoch 17/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.1576\n",
      "Epoch 18/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.1545\n",
      "Epoch 19/200\n",
      "6550/6550 [==============================] - 1s 144us/step - loss: 0.1573\n",
      "Epoch 20/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.1557\n",
      "Epoch 21/200\n",
      "6550/6550 [==============================] - 1s 129us/step - loss: 0.1498\n",
      "Epoch 22/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.1466\n",
      "Epoch 23/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.1424\n",
      "Epoch 24/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.1428\n",
      "Epoch 25/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.1415\n",
      "Epoch 26/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.1394\n",
      "Epoch 27/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.1350\n",
      "Epoch 28/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.1349\n",
      "Epoch 29/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.1356\n",
      "Epoch 30/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.1283\n",
      "Epoch 31/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.1328\n",
      "Epoch 32/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.1331\n",
      "Epoch 33/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.1286\n",
      "Epoch 34/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.1275\n",
      "Epoch 35/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.1220\n",
      "Epoch 36/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.1237\n",
      "Epoch 37/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.1236\n",
      "Epoch 38/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.1266\n",
      "Epoch 39/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.1193\n",
      "Epoch 40/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.1229\n",
      "Epoch 41/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.1200\n",
      "Epoch 42/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.1163\n",
      "Epoch 43/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.1202\n",
      "Epoch 44/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.1156\n",
      "Epoch 45/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.1158\n",
      "Epoch 46/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.1169\n",
      "Epoch 47/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.1129\n",
      "Epoch 48/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.1119\n",
      "Epoch 49/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.1141\n",
      "Epoch 50/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.1119\n",
      "Epoch 51/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.1137\n",
      "Epoch 52/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.1127\n",
      "Epoch 53/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.1089\n",
      "Epoch 54/200\n",
      "6550/6550 [==============================] - 1s 141us/step - loss: 0.1093\n",
      "Epoch 55/200\n",
      "6550/6550 [==============================] - 1s 148us/step - loss: 0.1080\n",
      "Epoch 56/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.1043\n",
      "Epoch 57/200\n",
      "6550/6550 [==============================] - 1s 142us/step - loss: 0.1075\n",
      "Epoch 58/200\n",
      "6550/6550 [==============================] - 1s 141us/step - loss: 0.1109\n",
      "Epoch 59/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.1086\n",
      "Epoch 60/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.1073\n",
      "Epoch 61/200\n",
      "6550/6550 [==============================] - 1s 143us/step - loss: 0.1063\n",
      "Epoch 62/200\n",
      "6550/6550 [==============================] - 1s 145us/step - loss: 0.1040\n",
      "Epoch 63/200\n",
      "6550/6550 [==============================] - 1s 151us/step - loss: 0.1051\n",
      "Epoch 64/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.1036\n",
      "Epoch 65/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.1031\n",
      "Epoch 66/200\n",
      "6550/6550 [==============================] - 1s 139us/step - loss: 0.1045\n",
      "Epoch 67/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.1018\n",
      "Epoch 68/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.1031\n",
      "Epoch 69/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.1027\n",
      "Epoch 70/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.1030\n",
      "Epoch 71/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.1008\n",
      "Epoch 72/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.1001\n",
      "Epoch 73/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.1010\n",
      "Epoch 74/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.1019\n",
      "Epoch 75/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.1007\n",
      "Epoch 76/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.0958\n",
      "Epoch 77/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.0989\n",
      "Epoch 78/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0989\n",
      "Epoch 79/200\n",
      "6550/6550 [==============================] - 1s 139us/step - loss: 0.0985\n",
      "Epoch 80/200\n",
      "6550/6550 [==============================] - 1s 145us/step - loss: 0.0990\n",
      "Epoch 81/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.0981\n",
      "Epoch 82/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0947\n",
      "Epoch 83/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.0991\n",
      "Epoch 84/200\n",
      "6550/6550 [==============================] - 1s 139us/step - loss: 0.0998\n",
      "Epoch 85/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0979\n",
      "Epoch 86/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0967\n",
      "Epoch 87/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.0962\n",
      "Epoch 88/200\n",
      "6550/6550 [==============================] - 1s 139us/step - loss: 0.0932\n",
      "Epoch 89/200\n",
      "6550/6550 [==============================] - 1s 150us/step - loss: 0.0923\n",
      "Epoch 90/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0931\n",
      "Epoch 91/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0938\n",
      "Epoch 92/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.0935\n",
      "Epoch 93/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0935\n",
      "Epoch 94/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.0925\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.0926\n",
      "Epoch 96/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.0938\n",
      "Epoch 97/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.0922\n",
      "Epoch 98/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.0912\n",
      "Epoch 99/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.0909\n",
      "Epoch 100/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0908\n",
      "Epoch 101/200\n",
      "6550/6550 [==============================] - 1s 139us/step - loss: 0.0907\n",
      "Epoch 102/200\n",
      "6550/6550 [==============================] - 1s 140us/step - loss: 0.0896\n",
      "Epoch 103/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0915\n",
      "Epoch 104/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.0908\n",
      "Epoch 105/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0908\n",
      "Epoch 106/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0879\n",
      "Epoch 107/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0912\n",
      "Epoch 108/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0904\n",
      "Epoch 109/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.0911\n",
      "Epoch 110/200\n",
      "6550/6550 [==============================] - 1s 143us/step - loss: 0.0895\n",
      "Epoch 111/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.0874\n",
      "Epoch 112/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0916\n",
      "Epoch 113/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0860\n",
      "Epoch 114/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0863\n",
      "Epoch 115/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0886\n",
      "Epoch 116/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.0898\n",
      "Epoch 117/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0880\n",
      "Epoch 118/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.0869\n",
      "Epoch 119/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.0889\n",
      "Epoch 120/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0900\n",
      "Epoch 121/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0880\n",
      "Epoch 122/200\n",
      "6550/6550 [==============================] - 1s 145us/step - loss: 0.0870\n",
      "Epoch 123/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0843\n",
      "Epoch 124/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0868\n",
      "Epoch 125/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.0872\n",
      "Epoch 126/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.0871\n",
      "Epoch 127/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0859\n",
      "Epoch 128/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0845\n",
      "Epoch 129/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.0849\n",
      "Epoch 130/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0817\n",
      "Epoch 131/200\n",
      "6550/6550 [==============================] - 1s 145us/step - loss: 0.0836\n",
      "Epoch 132/200\n",
      "6550/6550 [==============================] - 1s 139us/step - loss: 0.0840\n",
      "Epoch 133/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0843\n",
      "Epoch 134/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0845\n",
      "Epoch 135/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0854\n",
      "Epoch 136/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.0844\n",
      "Epoch 137/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.0838\n",
      "Epoch 138/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.0817\n",
      "Epoch 139/200\n",
      "6550/6550 [==============================] - 1s 150us/step - loss: 0.0819\n",
      "Epoch 140/200\n",
      "6550/6550 [==============================] - 1s 145us/step - loss: 0.0832\n",
      "Epoch 141/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0849\n",
      "Epoch 142/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0827\n",
      "Epoch 143/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.0847\n",
      "Epoch 144/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0822\n",
      "Epoch 145/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0830\n",
      "Epoch 146/200\n",
      "6550/6550 [==============================] - 1s 141us/step - loss: 0.0831\n",
      "Epoch 147/200\n",
      "6550/6550 [==============================] - 1s 140us/step - loss: 0.0816\n",
      "Epoch 148/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0817\n",
      "Epoch 149/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0820\n",
      "Epoch 150/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0827\n",
      "Epoch 151/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0825\n",
      "Epoch 152/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0815\n",
      "Epoch 153/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0809\n",
      "Epoch 154/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0816\n",
      "Epoch 155/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0827\n",
      "Epoch 156/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.0829\n",
      "Epoch 157/200\n",
      "6550/6550 [==============================] - 1s 141us/step - loss: 0.0816\n",
      "Epoch 158/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.0809\n",
      "Epoch 159/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0796\n",
      "Epoch 160/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.0824\n",
      "Epoch 161/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0821\n",
      "Epoch 162/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0804\n",
      "Epoch 163/200\n",
      "6550/6550 [==============================] - 1s 145us/step - loss: 0.0814\n",
      "Epoch 164/200\n",
      "6550/6550 [==============================] - 1s 139us/step - loss: 0.0806\n",
      "Epoch 165/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0808\n",
      "Epoch 166/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0799\n",
      "Epoch 167/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0804\n",
      "Epoch 168/200\n",
      "6550/6550 [==============================] - 1s 138us/step - loss: 0.0800\n",
      "Epoch 169/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0798\n",
      "Epoch 170/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.0820\n",
      "Epoch 171/200\n",
      "6550/6550 [==============================] - 1s 139us/step - loss: 0.0798\n",
      "Epoch 172/200\n",
      "6550/6550 [==============================] - 1s 141us/step - loss: 0.0802\n",
      "Epoch 173/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0804\n",
      "Epoch 174/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0800\n",
      "Epoch 175/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0821\n",
      "Epoch 176/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.0778\n",
      "Epoch 177/200\n",
      "6550/6550 [==============================] - 1s 141us/step - loss: 0.0810\n",
      "Epoch 178/200\n",
      "6550/6550 [==============================] - 1s 141us/step - loss: 0.0792\n",
      "Epoch 179/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.0781\n",
      "Epoch 180/200\n",
      "6550/6550 [==============================] - 1s 140us/step - loss: 0.0793\n",
      "Epoch 181/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0778\n",
      "Epoch 182/200\n",
      "6550/6550 [==============================] - 1s 137us/step - loss: 0.0768\n",
      "Epoch 183/200\n",
      "6550/6550 [==============================] - 1s 142us/step - loss: 0.0791\n",
      "Epoch 184/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.0793\n",
      "Epoch 185/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0775\n",
      "Epoch 186/200\n",
      "6550/6550 [==============================] - 1s 136us/step - loss: 0.0783\n",
      "Epoch 187/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0772\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0775\n",
      "Epoch 189/200\n",
      "6550/6550 [==============================] - 1s 130us/step - loss: 0.0771\n",
      "Epoch 190/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0781\n",
      "Epoch 191/200\n",
      "6550/6550 [==============================] - 1s 140us/step - loss: 0.0792\n",
      "Epoch 192/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0790\n",
      "Epoch 193/200\n",
      "6550/6550 [==============================] - 1s 131us/step - loss: 0.0770\n",
      "Epoch 194/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0760\n",
      "Epoch 195/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0760\n",
      "Epoch 196/200\n",
      "6550/6550 [==============================] - 1s 134us/step - loss: 0.0779\n",
      "Epoch 197/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0755\n",
      "Epoch 198/200\n",
      "6550/6550 [==============================] - 1s 133us/step - loss: 0.0785\n",
      "Epoch 199/200\n",
      "6550/6550 [==============================] - 1s 132us/step - loss: 0.0775\n",
      "Epoch 200/200\n",
      "6550/6550 [==============================] - 1s 135us/step - loss: 0.0756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12754f850>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convmodel = conv_model()\n",
    "convmodel.fit(train_x, train_y, batch_size=40, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 0s 455us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5485877189826542"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 0s 238us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4417123108379511"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convmodel.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 0s 244us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4973203591391147"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convmodel.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([271., 272., 454., 411., 504., 559., 486., 441., 381., 480., 182.]),\n",
       " array([-1.  ,  0.  ,  0.25,  0.5 ,  0.75,  1.  ,  1.25,  1.5 ,  1.75,\n",
       "         2.  ,  2.25,  3.  ]),\n",
       " <a list of 11 Patch objects>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(labels, bins=[-1, 0, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.25, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([l for l in labels if l <= -0.5 and l >= -1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   4508.00\n",
       "mean       1.14\n",
       "std        0.78\n",
       "min       -1.64\n",
       "25%        0.59\n",
       "50%        1.14\n",
       "75%        1.72\n",
       "max        3.51\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecoli_df['value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df.groupby(('sequence', 'bacterium'))['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlap(row):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.8290654]]), array([-0.01057732]))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_, model.intercept_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
