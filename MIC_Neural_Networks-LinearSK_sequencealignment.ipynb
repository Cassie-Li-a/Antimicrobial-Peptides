{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "%matplotlib inline\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The scripts stored the outputs as dictionaries.\n",
    "all_results = []\n",
    "for f in os.listdir('.'):\n",
    "    if '.data' in f:\n",
    "        with open(f, 'r') as g:\n",
    "            all_results.append(ast.literal_eval(g.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize units of MIC\n",
    "def standardize_to_uM(concentration, unit, sequence):\n",
    "    concentration = concentration.replace(' ', '')\n",
    "    try:\n",
    "        concentration = float(concentration)\n",
    "    except:\n",
    "        return None\n",
    "    if unit == 'uM' or unit == u'\\xb5M' or unit == u'uM)':\n",
    "        return concentration\n",
    "    elif unit == 'ug/ml' or unit == u'\\xb5g/ml' or unit == u'ug/ml)':\n",
    "        try:\n",
    "            molWt = ProteinAnalysis(sequence).molecular_weight()\n",
    "        except ValueError:\n",
    "            return None\n",
    "        return concentration * 1000/molWt\n",
    "    elif unit == 'nmol/g' or unit == 'pmol/mg':\n",
    "        #1g, at density of 1g/mL, is 1mL, so nmol/g is nmol/mL = umol/L = uM yay!\n",
    "        return concentration\n",
    "    else:\n",
    "        # print 'Unit not recognized: ' + unit\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enter an element of a result dictionary into df-ready row\n",
    "def convert_result_to_rows(sequence, result):\n",
    "    rows = []\n",
    "    if 'bacteria' not in result:\n",
    "        return rows\n",
    "    for bacterium, strain in result['bacteria']:\n",
    "        \n",
    "        rows.append({\n",
    "            'bacterium': bacterium,\n",
    "            'strain': strain,\n",
    "            'sequence': sequence.upper(),\n",
    "            'url_source': result['url_sources'][0],\n",
    "            'value': standardize_to_uM(\n",
    "                result['bacteria'][(bacterium, strain)]['value'],\n",
    "                result['bacteria'][(bacterium, strain)]['unit'],\n",
    "                sequence\n",
    "            ),\n",
    "            'modifications': result['modifications'] if 'modifications' in result else [],\n",
    "            'unit': 'uM'\n",
    "        })\n",
    "        if rows[-1]['value']:\n",
    "            rows[-1]['value'] = np.log10(rows[-1]['value'])\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all the rows into an array\n",
    "rows = []\n",
    "for result_set in all_results:\n",
    "    for sequence in result_set:\n",
    "        for row in convert_result_to_rows(sequence, result_set[sequence]):\n",
    "            rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct the df\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dataframe length before removing bad chars:', 62494)\n",
      "('Dataframe length after removing bad chars:', 57697)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe length before removing bad chars:\", len(df))\n",
    "# Remove sequences with amino acids that aren't well-defined\n",
    "def strip_sequences_with_char(df, bad_char):\n",
    "    return df[~df.sequence.str.contains(bad_char)]\n",
    "\n",
    "for bad_char in ['U', 'X', 'Z']:\n",
    "    df = strip_sequences_with_char(df, bad_char)\n",
    "print(\"Dataframe length after removing bad chars:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll want to strip off any sequences with modifications that could be hard to replicate\n",
    "# Their effects are too complex for the model\n",
    "def is_modified(modifications_list):\n",
    "    return len(modifications_list) > 0\n",
    "\n",
    "df['is_modified'] = df.modifications.apply(is_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# However, C-Terminal Amidation is common enough that we make an exception\n",
    "def has_non_cterminal_modification(modifications_list):\n",
    "    return any(['C-Term' not in modification for modification in modifications_list])\n",
    "\n",
    "df['has_non_cterminal_modification'] = df.modifications.apply(has_non_cterminal_modification)\n",
    "\n",
    "df['has_cterminal_modification'] = df.is_modified & ~df.has_non_cterminal_modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean sequences by removing newlines and one improper sequence\n",
    "df.sequence = df.sequence.str.strip()\n",
    "df = df.loc[df.sequence != '/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exclude sequences with modifications\n",
    "# Exclude rows from YADAMP and CAMP for having no modification data\n",
    "#     Unless that sequence is in another DB\n",
    "\n",
    "df = df.loc[df.has_non_cterminal_modification == False]\n",
    "\n",
    "no_modification_data_sources = ['camp3', 'yadamp']\n",
    "\n",
    "def datasource_has_modifications(cell):\n",
    "    # Everything except CAMP and YADAMP has modification data\n",
    "    return not any([s in cell for s in no_modification_data_sources])\n",
    "\n",
    "df['_datasource_has_modifications'] = df['url_source'].apply(datasource_has_modifications)\n",
    "\n",
    "sequences_containing_modifications = set(df.loc[df._datasource_has_modifications == True, 'sequence'])\n",
    "def sequence_has_modification_data(cell):\n",
    "    # If the sequence is labeled modifictationless in another database it's OK\n",
    "    return cell in sequences_containing_modifications\n",
    "\n",
    "df['_sequence_has_modifications'] = df['sequence'].apply(sequence_has_modification_data)\n",
    "\n",
    "df['modification_verified'] = df['_sequence_has_modifications'] | df['_datasource_has_modifications']\n",
    "\n",
    "df = df.loc[df.modification_verified == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHARACTER_DICT = set([character for sequence in df.sequence for character in sequence])\n",
    "MAX_SEQUENCE_LENGTH = int(df.sequence.str.len().describe(percentiles=[0.95])['95%'])\n",
    "\n",
    "# Each amino acid its own group\n",
    "character_to_index = {\n",
    "    (character): i\n",
    "    for i, character in enumerate(CHARACTER_DICT)\n",
    "}\n",
    "\n",
    "# Group them together heavily\n",
    "\"\"\"character_to_index = {\n",
    "    ('R', 'K', 'H'): 0,\n",
    "    ('D', 'E'): 1,\n",
    "    ('S', 'T', 'N', 'Q', 'C'): 2,\n",
    "    ('A', 'V', 'I', 'L', 'M', 'F', 'Y', 'W', 'P', 'G'): 3,\n",
    "}\n",
    "\n",
    "# Group them together more sparingly\n",
    "character_to_index = {\n",
    "    ('R'): 0,\n",
    "    ('H'): 1,\n",
    "    ('K'): 2,\n",
    "    ('D', 'E'): 3,\n",
    "    ('S', 'T', 'N', 'Q', 'C'): 4,\n",
    "    ('G', 'P'): 5,\n",
    "    ('A', 'V', 'I', 'L', 'M'): 6,\n",
    "    ('F', 'Y', 'W'): 7,\n",
    "}\"\"\"\n",
    "\n",
    "index2character = {\n",
    "    value: key\n",
    "    for key, value in character_to_index.items()\n",
    "}\n",
    "\n",
    "def sequence_to_vector(sequence, cterminal_amidation):\n",
    "# It looks like this truncates any sequence after max_sequence_length (which is length of 95th percentile longest peptide)\n",
    "# I just add cterminal amidation as the amino acid after the last real amino acid (if the amino acid gets truncated\n",
    "# then the cterminal amidation also gets cut off)\n",
    "    default = np.zeros([MAX_SEQUENCE_LENGTH, len(character_to_index) + 1])\n",
    "    for i, character in enumerate(sequence[:MAX_SEQUENCE_LENGTH]):\n",
    "        default[i][character_to_index[character]] = 1\n",
    "    if len(sequence)<MAX_SEQUENCE_LENGTH:\n",
    "        default[len(sequence)][-1]=cterminal_amidation\n",
    "    return default\n",
    "\n",
    "def old_sequence_to_vector(sequence, cterminal_amidation):\n",
    "    default = np.zeros([MAX_SEQUENCE_LENGTH, len(character_to_index) + 1])\n",
    "    for i, character in enumerate(sequence[:MAX_SEQUENCE_LENGTH]):\n",
    "        default[i][character_to_index[character]] = 1\n",
    "        default[i][-1] = cterminal_amidation\n",
    "    return default\n",
    "\n",
    "def find_character(character2index, character):\n",
    "    for key in character2index:\n",
    "        if character in key:\n",
    "            return character2index[key]\n",
    "    return -2\n",
    "\n",
    "def row_to_vector(row, shuffle_sequence=False):\n",
    "    sequence = list(row['sequence'])\n",
    "    if shuffle_sequence:\n",
    "        random.shuffle(sequence)\n",
    "    cterminal_amidation = row['has_cterminal_modification']\n",
    "    return sequence_to_vector(sequence,cterminal_amidation)\n",
    "\n",
    "def old_row_to_vector(row, shuffle_sequence=False):\n",
    "    sequence = list(row['sequence'])\n",
    "    if shuffle_sequence:\n",
    "        random.shuffle(sequence)\n",
    "    cterminal_amidation = row['has_cterminal_modification']\n",
    "    default = np.zeros([MAX_SEQUENCE_LENGTH, len(character_to_index) + 1])\n",
    "\n",
    "    for i, character in enumerate(sequence[:MAX_SEQUENCE_LENGTH]):\n",
    "        default[i][find_character(character_to_index, character)] = 1\n",
    "        default[i][-1] = cterminal_amidation\n",
    "\n",
    "    return default\n",
    "\n",
    "def vector_to_amp(vector):\n",
    "    sequence = ''\n",
    "    has_cterm = False\n",
    "    for v in vector:\n",
    "        nonzeros = np.argwhere(v[:len(character_to_index)])\n",
    "        if len(nonzeros) > 1:\n",
    "            print(\"?????\")\n",
    "        elif len(nonzeros) == 0:\n",
    "            sequence += '_'\n",
    "        else:\n",
    "            sequence += index2character[np.argwhere(v)[0][0]]  # First one\n",
    "        if v[-1]>0:\n",
    "            has_cterm=True\n",
    "    return {\n",
    "        'sequence': sequence,\n",
    "        'cterminal_amidation': has_cterm\n",
    "    }\n",
    "\n",
    "def bacterium_to_sample_weight(bacterium, intended_bacterium='E. coli'):\n",
    "    if intended_bacterium in bacterium:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def containing_bacterium(bacterium, df):\n",
    "    return df.loc[df.bacterium.str.contains(bacterium)]\n",
    "\n",
    "def average_over_databases(bacterium_df):\n",
    "    return bacterium_df.groupby('sequence')['value'].mean().dropna()\n",
    "\n",
    "staph = containing_bacterium('S. aureus', df)\n",
    "staph = average_over_databases(staph)\n",
    "\n",
    "ecoli = df.loc[df.bacterium.str.contains('E. coli')].groupby('sequence')['value'].mean().dropna()\n",
    "pseudomonas = df.loc[df.bacterium.str.contains('P. aeruginosa')].groupby('sequence')['value'].mean().dropna()\n",
    "streptococcus = df.loc[df.bacterium.str.contains('S. mutans')].groupby('sequence')['value'].mean().dropna()\n",
    "bacillus = df.loc[df.bacterium.str.contains('B. subtilis')].groupby('sequence')['value'].mean().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecoli</th>\n",
       "      <th>pseudomonas</th>\n",
       "      <th>streptococcus</th>\n",
       "      <th>staph</th>\n",
       "      <th>bacillus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ecoli</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pseudomonas</th>\n",
       "      <td>0.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>streptococcus</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>staph</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bacillus</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ecoli  pseudomonas  streptococcus  staph  bacillus\n",
       "ecoli           1.00         0.78           0.71   0.67      0.69\n",
       "pseudomonas     0.78         1.00           0.52   0.65      0.60\n",
       "streptococcus   0.71         0.52           1.00   0.83      0.82\n",
       "staph           0.67         0.65           0.83   1.00      0.67\n",
       "bacillus        0.69         0.60           0.82   0.67      1.00"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the correlation between bacteria\n",
    "# Note that Gram-Positivity seems to have a strong effect on correlation\n",
    "# E. coli and pseudomonas are highly correlated\n",
    "# While neither is correlated with streptococcus, staph or bacillus\n",
    "# Meanwhile, staph and streptococcus are strongly correlated as expected\n",
    "# As are bacillus and streptococcus\n",
    "# The lack of correlation between bacillus and staph is a mystery to me\n",
    "many_bacteria = pd.concat([ecoli, pseudomonas, streptococcus, staph, bacillus], axis=1).reset_index()\n",
    "many_bacteria.columns = ['index', 'ecoli', 'pseudomonas', 'streptococcus', 'staph', 'bacillus']\n",
    "many_bacteria.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since ecoli data and pseudomonas data are highly correlated, we will use some pseudomonas data in the model\n",
    "# (With a lower sample weight)\n",
    "ecoli_pseudomonas = many_bacteria.dropna(subset=('ecoli', 'pseudomonas'))\n",
    "x = np.array(ecoli_pseudomonas['pseudomonas']).reshape(-1, 1)\n",
    "y = np.array(ecoli_pseudomonas['ecoli']).reshape(-1, 1)\n",
    "pseudomonas_to_ecoli_model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bacterium_df(bacterium, df):\n",
    "    bdf = df.loc[(df.bacterium.str.contains(bacterium))].groupby(['sequence', 'bacterium'])\n",
    "    return bdf.mean().reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_bad_amino_acids(df, bad_amino_acids=('U', 'X', 'Z')):\n",
    "    for b in bad_amino_acids:\n",
    "        df = df.loc[~df.sequence.str.contains(b)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecoli_df = get_bacterium_df('E. coli', df)\n",
    "ecoli_df = strip_bad_amino_acids(ecoli_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12d44a7d0>"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b8fc550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MIC on E. coli is normally distributed-ish\n",
    "ecoli_df.value.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate the input vectors for our model\n",
    "# Each vector is two dimensional\n",
    "# The first dimension represents the number of characters in the sequence (46 characters)\n",
    "# Each character is a vector of length equal to the number of groupings of amino acids\n",
    "# This grouping can be 1-1 (each amino acid gets its own group), or coarser\n",
    "SHUFFLE_SEQUENCE = False\n",
    "cterminal_amidation = np.array(ecoli_df.has_cterminal_modification)\n",
    "\n",
    "vectors = []\n",
    "for row in ecoli_df.iterrows():\n",
    "    vectors.append(row_to_vector(row[1], shuffle_sequence=SHUFFLE_SEQUENCE))\n",
    "\n",
    "vectors = np.array(vectors)\n",
    "\n",
    "labels = np.array(ecoli_df.value)\n",
    "sample_weights = np.full(len(labels), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_random_sequence(alphabet, length_of_sequence_min=25, length_of_sequence_max=40):\n",
    "        sequence = ''\n",
    "        for _ in range(random.choice(range(length_of_sequence_min, length_of_sequence_max))):\n",
    "            sequence += random.choice(list(alphabet))\n",
    "        has_cterminal_modification = random.choice([0, 1])\n",
    "\n",
    "        return {\n",
    "            'sequence': sequence,\n",
    "            'has_cterminal_modification': has_cterminal_modification\n",
    "        }\n",
    "\n",
    "def add_random_negative_examples(vectors, labels, sample_weights, ratio, max_mic = None):\n",
    "    if not max_mic:\n",
    "        max_mic = max(labels)\n",
    "    # We will add randomly chosen sequences as negative examples\n",
    "    # We will double the length of our training set\n",
    "\n",
    "    len_vectors = ratio * len(vectors)\n",
    "    negative_rows = []\n",
    "    for i in range(len_vectors):\n",
    "        negative_rows.append(row_to_vector(generate_random_sequence(list(CHARACTER_DICT))))\n",
    "    negative_vectors = np.array(negative_rows)\n",
    "    vectors = np.concatenate((vectors, negative_vectors))\n",
    "    negative_labels = np.full(len_vectors, max_mic)\n",
    "    labels = np.concatenate((labels, negative_labels))\n",
    "    # Weight all samples equally\n",
    "    sample_weights = np.concatenate((sample_weights, np.full(len_vectors, 1)))\n",
    "    return vectors, labels, sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_MIC = 3.5\n",
    "vectors, labels, sample_weights = add_random_negative_examples(vectors, labels, sample_weights, ratio=1, max_mic=MAX_MIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector shape after adding negative examples\n",
      "(9016, 46, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vector shape after adding negative examples\")\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create simulated ecoli data from pseudomonas data\n",
    "bacteria_name = 'P. aeruginosa'\n",
    "pa_df = df.loc[(df.bacterium.str.contains(bacteria_name))].groupby(['sequence', 'bacterium'])\n",
    "pa_df = pa_df.mean().reset_index().dropna()\n",
    "\n",
    "pa_cterminal_amidation = np.array(pa_df.has_cterminal_modification)\n",
    "\n",
    "pa_vectors = []\n",
    "for row in pa_df.iterrows():\n",
    "    pa_vectors.append(row_to_vector(row[1], shuffle_sequence=SHUFFLE_SEQUENCE))\n",
    "\n",
    "pa_vectors = np.array(pa_vectors)\n",
    "\n",
    "pa_labels = np.array(pa_df.value.apply(pseudomonas_to_ecoli_model.predict))  # Interpolate using the linear model\n",
    "pa_sample_weights = np.array([0.5] * len(pa_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline error:\n",
      "1.6979921723869722\n",
      "Baseline error on measured examples only\n",
      "0.5995982451676932\n"
     ]
    }
   ],
   "source": [
    "average = np.mean(labels)\n",
    "squared_errors = sum([(label - average) ** 2 for label in labels])\n",
    "baseline_error = squared_errors/len(labels)\n",
    "print(\"Baseline error:\")\n",
    "print(baseline_error)\n",
    "measured_labels = [l for l in labels if l < MAX_MIC]\n",
    "average = np.mean(measured_labels)\n",
    "squared_errors = sum([(label - average) ** 2 for label in measured_labels])\n",
    "baseline_error = squared_errors/len(measured_labels)\n",
    "print(\"Baseline error on measured examples only\")\n",
    "print(baseline_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "linear_estimator = LinearRegression()\n",
    "#cross_val_score(linear_estimator, vectors.reshape(vectors.shape[0], -1)[:10], labels[:10])\n",
    "i = 200\n",
    "#cross_val_score(linear_estimator, np.full(i, 1).reshape(-1, 1), random_labels, scoring='neg_mean_squared_error')\n",
    "#linear_estimator.fit(vectors.reshape(vectors.shape[0], -1)[:95], labels[:95])\n",
    "linear_estimator.fit(np.full(shape=(len(labels)), fill_value=1).reshape(-1, 1), labels)\n",
    "#cross_val_score(linear_estimator, vectors.reshape(vectors.shape[0], -1), labels, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Dropout, LSTM, Conv2D, Conv1D, MaxPooling1D, MaxPooling2D, Flatten\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_train_test_splits(\n",
    "        vectors, labels,\n",
    "        extra_training_vectors=[], extra_training_labels=[], extra_sample_weights=[],\n",
    "        cutoff=0.85\n",
    "):\n",
    "    cutoff = int(cutoff * len(labels))\n",
    "    idx = range(len(vectors))\n",
    "    random.shuffle(idx)\n",
    "    reordered_vectors = vectors[idx]\n",
    "    reordered_labels = labels[idx]\n",
    "    reordered_sample_weights = sample_weights[idx]\n",
    "    if len(extra_training_vectors) > 0:\n",
    "        train_x = np.concatenate((reordered_vectors[:cutoff], extra_training_vectors))\n",
    "        train_y = np.concatenate((reordered_labels[:cutoff], extra_training_labels))\n",
    "        train_sample_weights = np.concatenate((reordered_sample_weights[:cutoff], pa_sample_weights))\n",
    "    else:\n",
    "        train_x = reordered_vectors[:cutoff]\n",
    "        train_y = reordered_labels[:cutoff]\n",
    "        train_sample_weights = reordered_sample_weights[:cutoff]\n",
    "    test_x = reordered_vectors[cutoff:]\n",
    "    test_y = reordered_labels[cutoff:]\n",
    "    return train_x, train_y, test_x, test_y, train_sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vanilla LSTM\n",
    "def baseline_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(LSTM(\n",
    "        128,\n",
    "        input_shape=(MAX_SEQUENCE_LENGTH, len(character_to_index) + 1),\n",
    "    ))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, kernel_initializer='normal'))\n",
    "    model.add(Dense(20, kernel_initializer='normal'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17820/17820 [==============================] - 61s 3ms/step - loss: 1.7907\n",
      "Epoch 2/100\n",
      " 8080/17820 [============>.................] - ETA: 31s - loss: 1.6299"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-ab664e2680c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_train_test_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_sample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jacobwitten/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/jacobwitten/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/jacobwitten/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jacobwitten/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jacobwitten/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jacobwitten/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jacobwitten/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/jacobwitten/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jacobwitten/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Doesn't work as well as conv model\n",
    "model = baseline_model()\n",
    "train_x, train_y, test_x, test_y, _ = generate_train_test_splits(vectors, labels, pa_vectors, pa_labels, pa_sample_weights)\n",
    "model.fit(train_x, train_y, sample_weight=[], batch_size=40, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM test error, MSE of log MIC\n",
      "1353/1353 [==============================] - 0s 263us/step\n",
      "0.2881708491403618\n"
     ]
    }
   ],
   "source": [
    "print(\"LSTM test error, MSE of log MIC\")\n",
    "print(model.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48717642"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(\n",
    "    [(actual - predicted) ** 2 \n",
    "     for actual, predicted in zip(test_y, model.predict(test_x)) if actual < MAX_MIC\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional NN\n",
    "def conv_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Conv1D(\n",
    "        64,\n",
    "        kernel_size = 5,\n",
    "        strides = 1,\n",
    "        activation = 'relu',\n",
    "        input_shape = (MAX_SEQUENCE_LENGTH, len(character_to_index) + 1)\n",
    "    ))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(64, 5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    #model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10156/10156 [==============================] - 4s 384us/step - loss: 0.8658\n",
      "Epoch 2/100\n",
      "10156/10156 [==============================] - 4s 351us/step - loss: 0.5011\n",
      "Epoch 3/100\n",
      "10156/10156 [==============================] - 3s 340us/step - loss: 0.4056\n",
      "Epoch 4/100\n",
      "10156/10156 [==============================] - 3s 280us/step - loss: 0.3405\n",
      "Epoch 5/100\n",
      "10156/10156 [==============================] - 3s 272us/step - loss: 0.2930\n",
      "Epoch 6/100\n",
      "10156/10156 [==============================] - 3s 323us/step - loss: 0.2573\n",
      "Epoch 7/100\n",
      "10156/10156 [==============================] - 3s 267us/step - loss: 0.2348\n",
      "Epoch 8/100\n",
      "10156/10156 [==============================] - 3s 271us/step - loss: 0.2216\n",
      "Epoch 9/100\n",
      "10156/10156 [==============================] - 3s 268us/step - loss: 0.2017\n",
      "Epoch 10/100\n",
      "10156/10156 [==============================] - 3s 265us/step - loss: 0.1848\n",
      "Epoch 11/100\n",
      "10156/10156 [==============================] - 3s 265us/step - loss: 0.1701\n",
      "Epoch 12/100\n",
      "10156/10156 [==============================] - 3s 266us/step - loss: 0.1628\n",
      "Epoch 13/100\n",
      "10156/10156 [==============================] - 3s 325us/step - loss: 0.1517\n",
      "Epoch 14/100\n",
      "10156/10156 [==============================] - 3s 280us/step - loss: 0.1426\n",
      "Epoch 15/100\n",
      "10156/10156 [==============================] - 3s 294us/step - loss: 0.1421\n",
      "Epoch 16/100\n",
      "10156/10156 [==============================] - 3s 330us/step - loss: 0.1364\n",
      "Epoch 17/100\n",
      "10156/10156 [==============================] - 3s 330us/step - loss: 0.1299\n",
      "Epoch 18/100\n",
      "10156/10156 [==============================] - 4s 380us/step - loss: 0.1269\n",
      "Epoch 19/100\n",
      "10156/10156 [==============================] - 3s 301us/step - loss: 0.1185\n",
      "Epoch 20/100\n",
      "10156/10156 [==============================] - 3s 272us/step - loss: 0.1145\n",
      "Epoch 21/100\n",
      "10156/10156 [==============================] - 3s 279us/step - loss: 0.1158\n",
      "Epoch 22/100\n",
      "10156/10156 [==============================] - 3s 271us/step - loss: 0.1116\n",
      "Epoch 23/100\n",
      "10156/10156 [==============================] - 3s 269us/step - loss: 0.1122\n",
      "Epoch 24/100\n",
      "10156/10156 [==============================] - 3s 260us/step - loss: 0.1157\n",
      "Epoch 25/100\n",
      "10156/10156 [==============================] - 3s 283us/step - loss: 0.1082\n",
      "Epoch 26/100\n",
      "10156/10156 [==============================] - 3s 290us/step - loss: 0.1018\n",
      "Epoch 27/100\n",
      "10156/10156 [==============================] - 3s 264us/step - loss: 0.1072\n",
      "Epoch 28/100\n",
      "10156/10156 [==============================] - 3s 272us/step - loss: 0.1006\n",
      "Epoch 29/100\n",
      "10156/10156 [==============================] - 3s 329us/step - loss: 0.1016\n",
      "Epoch 30/100\n",
      "10156/10156 [==============================] - 3s 317us/step - loss: 0.0976\n",
      "Epoch 31/100\n",
      "10156/10156 [==============================] - 3s 263us/step - loss: 0.0940\n",
      "Epoch 32/100\n",
      "10156/10156 [==============================] - 3s 273us/step - loss: 0.0967\n",
      "Epoch 33/100\n",
      "10156/10156 [==============================] - 3s 295us/step - loss: 0.0940\n",
      "Epoch 34/100\n",
      "10156/10156 [==============================] - 3s 284us/step - loss: 0.0915\n",
      "Epoch 35/100\n",
      "10156/10156 [==============================] - 4s 380us/step - loss: 0.0918\n",
      "Epoch 36/100\n",
      "10156/10156 [==============================] - 3s 302us/step - loss: 0.0910\n",
      "Epoch 37/100\n",
      "10156/10156 [==============================] - 3s 291us/step - loss: 0.0892\n",
      "Epoch 38/100\n",
      "10156/10156 [==============================] - 4s 360us/step - loss: 0.0900\n",
      "Epoch 39/100\n",
      "10156/10156 [==============================] - 3s 280us/step - loss: 0.0900\n",
      "Epoch 40/100\n",
      "10156/10156 [==============================] - 3s 267us/step - loss: 0.0909\n",
      "Epoch 41/100\n",
      "10156/10156 [==============================] - 3s 310us/step - loss: 0.0826\n",
      "Epoch 42/100\n",
      "10156/10156 [==============================] - 3s 275us/step - loss: 0.0874\n",
      "Epoch 43/100\n",
      "10156/10156 [==============================] - 3s 264us/step - loss: 0.0869\n",
      "Epoch 44/100\n",
      "10156/10156 [==============================] - 3s 307us/step - loss: 0.0842\n",
      "Epoch 45/100\n",
      "10156/10156 [==============================] - 4s 399us/step - loss: 0.0874\n",
      "Epoch 46/100\n",
      "10156/10156 [==============================] - 3s 300us/step - loss: 0.0802\n",
      "Epoch 47/100\n",
      "10156/10156 [==============================] - 3s 269us/step - loss: 0.0813\n",
      "Epoch 48/100\n",
      "10156/10156 [==============================] - 3s 298us/step - loss: 0.0815\n",
      "Epoch 49/100\n",
      "10156/10156 [==============================] - 3s 303us/step - loss: 0.0865\n",
      "Epoch 50/100\n",
      "10156/10156 [==============================] - 4s 351us/step - loss: 0.0812\n",
      "Epoch 51/100\n",
      "10156/10156 [==============================] - 4s 368us/step - loss: 0.0812\n",
      "Epoch 52/100\n",
      "10156/10156 [==============================] - 4s 359us/step - loss: 0.0798\n",
      "Epoch 53/100\n",
      "10156/10156 [==============================] - 4s 355us/step - loss: 0.0776\n",
      "Epoch 54/100\n",
      "10156/10156 [==============================] - 3s 305us/step - loss: 0.0765\n",
      "Epoch 55/100\n",
      "10156/10156 [==============================] - 3s 332us/step - loss: 0.0810\n",
      "Epoch 56/100\n",
      "10156/10156 [==============================] - 3s 269us/step - loss: 0.0766\n",
      "Epoch 57/100\n",
      "10156/10156 [==============================] - 3s 271us/step - loss: 0.0742\n",
      "Epoch 58/100\n",
      "10156/10156 [==============================] - 3s 298us/step - loss: 0.0734\n",
      "Epoch 59/100\n",
      "10156/10156 [==============================] - 3s 272us/step - loss: 0.0742\n",
      "Epoch 60/100\n",
      "10156/10156 [==============================] - 3s 310us/step - loss: 0.0759\n",
      "Epoch 61/100\n",
      "10156/10156 [==============================] - 3s 279us/step - loss: 0.0723\n",
      "Epoch 62/100\n",
      "10156/10156 [==============================] - 3s 272us/step - loss: 0.0816\n",
      "Epoch 63/100\n",
      "10156/10156 [==============================] - 3s 269us/step - loss: 0.0779\n",
      "Epoch 64/100\n",
      "10156/10156 [==============================] - 3s 273us/step - loss: 0.0712\n",
      "Epoch 65/100\n",
      "10156/10156 [==============================] - 3s 273us/step - loss: 0.0710\n",
      "Epoch 66/100\n",
      "10156/10156 [==============================] - 3s 275us/step - loss: 0.0734\n",
      "Epoch 67/100\n",
      "10156/10156 [==============================] - 3s 266us/step - loss: 0.0731\n",
      "Epoch 68/100\n",
      "10156/10156 [==============================] - 4s 371us/step - loss: 0.0723\n",
      "Epoch 69/100\n",
      "10156/10156 [==============================] - 4s 353us/step - loss: 0.0728\n",
      "Epoch 70/100\n",
      "10156/10156 [==============================] - 3s 323us/step - loss: 0.0708\n",
      "Epoch 71/100\n",
      "10156/10156 [==============================] - 3s 308us/step - loss: 0.0693\n",
      "Epoch 72/100\n",
      "10156/10156 [==============================] - 3s 285us/step - loss: 0.0692\n",
      "Epoch 73/100\n",
      "10156/10156 [==============================] - 3s 279us/step - loss: 0.0689\n",
      "Epoch 74/100\n",
      "10156/10156 [==============================] - 3s 294us/step - loss: 0.0809\n",
      "Epoch 75/100\n",
      "10156/10156 [==============================] - 3s 276us/step - loss: 0.0721\n",
      "Epoch 76/100\n",
      "10156/10156 [==============================] - 3s 280us/step - loss: 0.0686\n",
      "Epoch 77/100\n",
      "10156/10156 [==============================] - 3s 286us/step - loss: 0.0713\n",
      "Epoch 78/100\n",
      "10156/10156 [==============================] - 3s 313us/step - loss: 0.0700\n",
      "Epoch 79/100\n",
      "10156/10156 [==============================] - 4s 381us/step - loss: 0.0683\n",
      "Epoch 80/100\n",
      "10156/10156 [==============================] - 4s 369us/step - loss: 0.0669\n",
      "Epoch 81/100\n",
      "10156/10156 [==============================] - 4s 358us/step - loss: 0.0683\n",
      "Epoch 82/100\n",
      "10156/10156 [==============================] - 4s 375us/step - loss: 0.0685\n",
      "Epoch 83/100\n",
      "10156/10156 [==============================] - 4s 356us/step - loss: 0.0671\n",
      "Epoch 84/100\n",
      "10156/10156 [==============================] - 3s 336us/step - loss: 0.0640\n",
      "Epoch 85/100\n",
      "10156/10156 [==============================] - 3s 330us/step - loss: 0.0679\n",
      "Epoch 86/100\n",
      "10156/10156 [==============================] - 3s 287us/step - loss: 0.0670\n",
      "Epoch 87/100\n",
      "10156/10156 [==============================] - 3s 309us/step - loss: 0.0714\n",
      "Epoch 88/100\n",
      "10156/10156 [==============================] - 3s 330us/step - loss: 0.0701\n",
      "Epoch 89/100\n",
      "10156/10156 [==============================] - 3s 279us/step - loss: 0.0669\n",
      "Epoch 90/100\n",
      "10156/10156 [==============================] - 3s 277us/step - loss: 0.0667\n",
      "Epoch 91/100\n",
      "10156/10156 [==============================] - 3s 281us/step - loss: 0.0643\n",
      "Epoch 92/100\n",
      "10156/10156 [==============================] - 3s 275us/step - loss: 0.0618\n",
      "Epoch 93/100\n",
      "10156/10156 [==============================] - 3s 276us/step - loss: 0.0639\n",
      "Epoch 94/100\n",
      "10156/10156 [==============================] - 3s 278us/step - loss: 0.0649\n",
      "Epoch 95/100\n",
      "10156/10156 [==============================] - 3s 282us/step - loss: 0.0619\n",
      "Epoch 96/100\n",
      "10156/10156 [==============================] - 3s 276us/step - loss: 0.0669\n",
      "Epoch 97/100\n",
      "10156/10156 [==============================] - 3s 276us/step - loss: 0.0651\n",
      "Epoch 98/100\n",
      "10156/10156 [==============================] - 3s 281us/step - loss: 0.0651\n",
      "Epoch 99/100\n",
      "10156/10156 [==============================] - 3s 283us/step - loss: 0.0636\n",
      "Epoch 100/100\n",
      "10156/10156 [==============================] - 4s 346us/step - loss: 0.0639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11fdc0e10>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convmodel = conv_model()\n",
    "train_x, train_y, test_x, test_y, _ = generate_train_test_splits(vectors, labels, pa_vectors, pa_labels, pa_sample_weights)\n",
    "convmodel.fit(train_x, train_y, batch_size=40, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN test error, MSE of log MIC\n",
      "1353/1353 [==============================] - 0s 306us/step\n",
      "0.18398004318728592\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN test error, MSE of log MIC\")\n",
    "print(convmodel.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN test error, MSE of log MIC\n",
      "2705/2705 [==============================] - 1s 193us/step\n",
      "0.10254753295077414\n"
     ]
    }
   ],
   "source": [
    "# THIS IS THE OLD ONE\n",
    "print(\"CNN test error, MSE of log MIC\")\n",
    "print(convmodel.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN test error on measured examples only\n",
      "0.27704197\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN test error on measured examples only\")\n",
    "print(np.mean(\n",
    "    [(actual - predicted) ** 2 \n",
    "     for actual, predicted in zip(test_y, convmodel.predict(test_x)) if actual < MAX_MIC\n",
    "    ]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN test error on measured examples only\n",
      "0.38956055\n"
     ]
    }
   ],
   "source": [
    "# THIS IS THE OLD ONE\n",
    "print(\"CNN test error on measured examples only\")\n",
    "print(np.mean(\n",
    "    [(actual - predicted) ** 2 \n",
    "     for actual, predicted in zip(test_y, convmodel.predict(test_x)) if actual < MAX_MIC\n",
    "    ]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN test error, MSE of log MIC (RANDOM SHUFFLED SEQUENCE)\n",
      "1353/1353 [==============================] - 0s 106us/step\n",
      "0.17386886583199257\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN test error, MSE of log MIC (RANDOM SHUFFLED SEQUENCE)\")\n",
    "print(convmodel.evaluate(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN test error on measured examples only (RANDOM SHUFFLED SEQUENCE)\n",
      "0.29721802\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN test error on measured examples only (RANDOM SHUFFLED SEQUENCE)\")\n",
    "print(np.mean(\n",
    "    [(actual - predicted) ** 2 \n",
    "     for actual, predicted in zip(test_y, convmodel.predict(test_x)) if actual < MAX_MIC\n",
    "    ]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scales={'Eisenberg':{'A':  0.25, 'R': -1.80, 'N': -0.64,'D': -0.72, 'C':  0.04, 'Q': -0.69,'E': -0.62, 'G':  0.16, 'H': -0.40,'I':  0.73, 'L':  0.53, 'K': -1.10,'M':  0.26, 'F':  0.61, 'P': -0.07,'S': -0.26, 'T': -0.18, 'W':  0.37,'Y':  0.02, 'V':  0.54},\n",
    "'Normalized_consensus':{'A':0.62,'C':0.29,'D':-0.9,'E':-0.74,'F':1.19,'G':0.48,'H':-0.4,'I':1.38,'K':-1.5,'L':1.06,'M':0.64,'N':-0.78,'P':0.12,'Q':-0.85,'R':-2.53,'S':-0.18,'T':-.05,'V':1.08,'W':0.81,'Y':0.26}}\n",
    "\n",
    "def hydrophobic_moment(sequence,scale='Normalized_consensus',angle=0,is_in_degrees=True,normalize=True):\n",
    "    # Angle should be 100 for alpha helix, 180 for beta sheet\n",
    "    hscale=scales[scale]\n",
    "    sin_sum = 0\n",
    "    cos_sum = 0\n",
    "    moment=0\n",
    "    for i in range(len(sequence)):\n",
    "        hp=hscale[sequence[i]]\n",
    "        angle_in_radians=i*angle\n",
    "        if is_in_degrees:\n",
    "            angle_in_radians = (i*angle)*math.pi/180.0\n",
    "        sin_sum += hp*math.sin(angle_in_radians)\n",
    "        cos_sum += hp*math.cos(angle_in_radians)\n",
    "    moment = math.sqrt(sin_sum**2+cos_sum**2)\n",
    "    if normalize:\n",
    "        moment = moment/len(sequence)\n",
    "    return moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "random_sample() takes at most 1 positional argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-0510c6d4c7f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mamp_hydrophobic_moments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mecoli_amps_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhydrophobic_moment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshuffled_ecoli_amps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mecoli_amps_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Randomly shuffled AMP sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mshuffled_amp_hydrophobic_moments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffled_ecoli_amps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhydrophobic_moment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jacobwitten/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-0510c6d4c7f5>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mamp_hydrophobic_moments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mecoli_amps_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhydrophobic_moment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshuffled_ecoli_amps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mecoli_amps_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Randomly shuffled AMP sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mshuffled_amp_hydrophobic_moments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffled_ecoli_amps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhydrophobic_moment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.random_sample\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: random_sample() takes at most 1 positional argument (2 given)"
     ]
    }
   ],
   "source": [
    "ecoli_amps_sequence = ecoli_df['sequence']\n",
    "amp_hydrophobic_moments = ecoli_amps_sequence.apply(hydrophobic_moment)\n",
    "\n",
    "shuffled_ecoli_amps = ecoli_amps_sequence.apply(lambda x: ''.join(random.sample(x, len(x))))\n",
    "# Randomly shuffled AMP sequences\n",
    "shuffled_amp_hydrophobic_moments = shuffled_ecoli_amps.apply(hydrophobic_moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'amp_hydrophobic_moments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-db4c1122e858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_random_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacter_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamp_hydrophobic_moments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrandom_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_seqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrandom_hydrophobic_moments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhydrophobic_moment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'amp_hydrophobic_moments' is not defined"
     ]
    }
   ],
   "source": [
    "random_seqs = [generate_random_sequence(character_dict) for i in range(len(amp_hydrophobic_moments))]\n",
    "random_sequences = pd.Series([s['sequence'] for s in random_seqs])\n",
    "random_hydrophobic_moments = random_sequences.apply(hydrophobic_moment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hydrophobic_moments = pd.concat(\n",
    "    [amp_hydrophobic_moments, shuffled_amp_hydrophobic_moments, random_hydrophobic_moments],\n",
    "    axis=1\n",
    ")\n",
    "hydrophobic_moments.columns = ['AMPs', 'Shuffled AMPs', 'Random Peptides']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMPs</th>\n",
       "      <th>Shuffled AMPs</th>\n",
       "      <th>Random Peptides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4508.00</td>\n",
       "      <td>4508.00</td>\n",
       "      <td>4508.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.84</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AMPs  Shuffled AMPs  Random Peptides\n",
       "count 4508.00        4508.00          4508.00\n",
       "mean     0.29           0.29             0.14\n",
       "std      0.23           0.23             0.10\n",
       "min      0.00           0.00             0.00\n",
       "25%      0.12           0.12             0.06\n",
       "50%      0.24           0.24             0.12\n",
       "75%      0.40           0.40             0.20\n",
       "max      1.84           1.84             0.66"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydrophobic_moments.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  12.,   44.,  154.,  550.,  939., 1014.,  960.,  676.,  100.,\n",
       "          57.]),\n",
       " array([-1.64059182, -1.13673863, -0.63288545, -0.12903227,  0.37482091,\n",
       "         0.8786741 ,  1.38252728,  1.88638046,  2.39023364,  2.89408683,\n",
       "         3.39794001]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([l for l in labels if l < 3.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_peptide(peptide, model):\n",
    "    sequence = peptide['sequence']\n",
    "    cterm = peptide['has_cterminal_modification']\n",
    "    return model.predict(row_to_vector(\n",
    "        {'sequence': sequence, 'has_cterminal_modification': int(cterm)}\n",
    "    ).reshape(-1, MAX_SEQUENCE_LENGTH, len(character_to_index) + 1))\n",
    "\n",
    "\n",
    "def find_nearby_sequences(sequence, old_sequences=None, character_dict=CHARACTER_DICT):\n",
    "    new_sequences = set()\n",
    "    if old_sequences == None:\n",
    "        old_sequences = set()\n",
    "\n",
    "    for i in range(len(sequence)):\n",
    "        for c1 in character_dict:\n",
    "            for j in range(i + 1, len(sequence)):\n",
    "                for c2 in character_dict:\n",
    "                    new_sequence = sequence[:i] + c1 + sequence[i+1:j] + c2 + sequence[j+1:]\n",
    "                    for cterm in (True, False):\n",
    "                        ns_dict = {'sequence': new_sequence, 'has_cterminal_modification': cterm}\n",
    "                        new_sequences.add(frozenset(ns_dict.items()))\n",
    "    return old_sequences | new_sequences\n",
    "\n",
    "def evaluate_peptides(peptides, model):\n",
    "    return model.predict(\n",
    "        np.array(\n",
    "            [row_to_vector(dict(p)) for p in peptides]\n",
    "        ).reshape(\n",
    "            -1, MAX_SEQUENCE_LENGTH, len(character_to_index) + 1\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_sequence = generate_random_sequence(alphabet=list(CHARACTER_DICT))['sequence']\n",
    "nearbys = find_nearby_sequences(random_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset([('has_cterminal_modification', False), ('sequence', u'CLHLQHKLYNLTELGSLYTANTCCPLMG')])\n"
     ]
    }
   ],
   "source": [
    "print(min(nearbys, key=lambda x: evaluate_peptide(dict(x), convmodel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.495714]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_peptide({'has_cterminal_modification': False, 'sequence': u'MKFSYTNAPPCCTMEHWFYMSCCQNNE'}, convmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5059607],\n",
       "       [3.495861 ],\n",
       "       [3.502077 ],\n",
       "       ...,\n",
       "       [3.5038774],\n",
       "       [3.5069056],\n",
       "       [3.5053856]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_peptides(nearbys, convmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearby_peptide_vectors(peptide_vector):\n",
    "    nearby_vectors = []\n",
    "    for i in range(len(peptide_vector)):\n",
    "#         print peptide_vector[i]\n",
    "        if np.sum(peptide_vector[i][:len(peptide_vector[i]-1)])>0.5:\n",
    "            for j in range(len(peptide_vector[i]) - 1):  # - 1 because of amidation\n",
    "                v = np.zeros(len(peptide_vector[i]))\n",
    "                v[-1] = peptide_vector[0][-1]\n",
    "                v[j] = 1\n",
    "                new_vector = np.concatenate([\n",
    "                    peptide_vector[:i],\n",
    "                    v.reshape(-1, len(peptide_vector[i])),\n",
    "                    peptide_vector[i+1:]\n",
    "                ])\n",
    "                if is_acceptable(vector_to_amp(new_vector)['sequence']):\n",
    "                    nearby_vectors.append(new_vector)\n",
    "                else:\n",
    "                    print 'unacceptable! '+repr(vector_to_amp(new_vector)['sequence'])\n",
    "#                     cterm_flipped = deepcopy(new_vector)\n",
    "#                     reverse_cterm = (new_vector[0][-1] + 1) % 2\n",
    "#                     for c in cterm_flipped:\n",
    "#                         c[-1] = reverse_cterm\n",
    "#                     nearby_vectors.append(cterm_flipped)\n",
    "#         else:\n",
    "#             print 'Nope!'+repr(i)\n",
    "    return nearby_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = vectors[0]\n",
    "(np.concatenate([v[:9], v[10:11], v[10:]]) == v).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vs = nearby_peptide_vectors(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import pairwise2\n",
    "from Bio.SubsMat import MatrixInfo as matlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_acceptable(sequence_with_padding):\n",
    "    at_underscore=False\n",
    "    for char in sequence_with_padding:\n",
    "        if char == '_':\n",
    "            at_underscore=True\n",
    "        elif at_underscore:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_sequence(cdict=CHARACTER_DICT,min_seq_length=10):\n",
    "    s = generate_random_sequence(cdict,length_of_sequence_min=min_seq_length)\n",
    "    v = row_to_vector(s)\n",
    "    last=''\n",
    "    for i in range(100):\n",
    "        vs = nearby_peptide_vectors(v)\n",
    "        ps = convmodel.predict(np.array(vs))\n",
    "        best_i = min(range(len(ps)), key=lambda x: ps[x])\n",
    "        v = vs[best_i]\n",
    "        if vector_to_amp(v)['sequence']==last:\n",
    "            break\n",
    "        last=vector_to_amp(v)['sequence']\n",
    "    return vector_to_amp(v), ps[best_i][0]\n",
    "\n",
    "def generate_random_sequences(cdict=CHARACTER_DICT,min_seq_length=10):\n",
    "    s = generate_random_sequence(cdict,length_of_sequence_min=min_seq_length)\n",
    "    v = row_to_vector(s)\n",
    "    last=''\n",
    "    p=convmodel.predict(np.array([v]))\n",
    "    return vector_to_amp(v), p[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'cterminal_amidation': False, 'sequence': u'CEMNIDQISFQGHAWTWAEASMSYQRFNLRR_______________'}, {'cterminal_amidation': False, 'sequence': u'CFLCLSKTEERQPPWWHTGL__________________________'}, {'cterminal_amidation': False, 'sequence': u'GGMLKVLNVYGRCTGRHTKI__________________________'}, {'cterminal_amidation': False, 'sequence': u'RKWFKYCITVWQ__________________________________'}, {'cterminal_amidation': False, 'sequence': u'TDWFVSILLNSNCQKHNTPLYGY_______________________'}, {'cterminal_amidation': False, 'sequence': u'STDRLLYSFGVRAKFRRTVYRQYIWA____________________'}, {'cterminal_amidation': False, 'sequence': u'GWWGTCTRGPQFTITLLH____________________________'}, {'cterminal_amidation': True, 'sequence': u'RKWRVKRIFW____________________________________'}, {'cterminal_amidation': False, 'sequence': u'IERKKWPIGKVCRNRYGRKIRR________________________'}, {'cterminal_amidation': False, 'sequence': u'NNWKTSSCARLYIRNTSYGIYIPL______________________'}]\n",
      "[3.0303533, -0.5222174, -0.5406635, -0.018530548, -0.633139, -0.7726675, -0.17883071, -0.038147092, -0.7141862, -0.69088924]\n"
     ]
    }
   ],
   "source": [
    "nseqs=10\n",
    "sequences=['']*nseqs\n",
    "pred_log_mics=[0]*nseqs\n",
    "for i in range(nseqs):\n",
    "    seq,plm=generate_sequence()\n",
    "    sequences[i]=seq\n",
    "    pred_log_mics[i]=plm\n",
    "print sequences\n",
    "print pred_log_mics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'cterminal_amidation': False, 'sequence': u'MTECDVHHQVHSNEPHFFPKRHRDMFCIS_________________'}, {'cterminal_amidation': False, 'sequence': u'DSGMHMTRKQIEFCVRCAAAN_________________________'}, {'cterminal_amidation': False, 'sequence': u'ICYHMYEVPMSVSDMIRHWFFGE_______________________'}, {'cterminal_amidation': False, 'sequence': u'NRCWCVQCEQHFNKYDVDTWRSPQNDNVDAVLRAFIE_________'}, {'cterminal_amidation': False, 'sequence': u'MSYTRRVLYH____________________________________'}, {'cterminal_amidation': True, 'sequence': u'GNSFHTYKNFLMVAV_______________________________'}, {'cterminal_amidation': False, 'sequence': u'VITLDSIKENTDVEDVQAAIVYKIFPGQGD________________'}, {'cterminal_amidation': True, 'sequence': u'KPFIHVPMCNM___________________________________'}, {'cterminal_amidation': True, 'sequence': u'DMIPWKWMGRIRLDTRMFCLVYRGE_____________________'}, {'cterminal_amidation': True, 'sequence': u'ANWMGPPAWQL___________________________________'}]\n",
      "[3.4446352, 1.3010713, 3.4469535, 3.4841344, 1.4903101, 2.0109158, 3.4126198, 2.286308, 3.4866846, 2.1532512]\n"
     ]
    }
   ],
   "source": [
    "nseqs=10\n",
    "sequences=['']*nseqs\n",
    "pred_log_mics=[0]*nseqs\n",
    "for i in range(nseqs):\n",
    "    seq,plm=generate_random_sequences()\n",
    "    sequences[i]=seq\n",
    "    pred_log_mics[i]=plm\n",
    "print sequences\n",
    "print pred_log_mics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 9 8 4]\n",
      "STDRLLYSFGVRAKFRRTVYRQYIWA\n",
      "-0.7726675\n",
      "-STDRLLYSFGVRA---KFRRTVYRQYIWA--\n",
      "    |||||||||||||||||\n",
      "KFFARLLAS--VRAAVKKFRKKPRLIGLSTLL\n",
      "  Score=44\n",
      "\n",
      "([0.12278864701782083, 0.20286915096955999, 0.3011538461538461], [20.600000000000023, 43.60000000000035, 75.49999999999999])\n",
      "\n",
      "\n",
      "NNWKTSSCARLYIRNTSYGIYIPL\n",
      "-0.69088924\n",
      "------------NNWKTSSCARLYIRNTSYGIYIPL\n",
      "              ||||||||||||||\n",
      "SIITMTKEAKLPQSWKQIAC-RLY--NTC-------\n",
      "  Score=39\n",
      "\n",
      "([0.17389519071164913, 0.18354438021502917, 0.23750000000000013], [47.3000000000004, 48.40000000000042, 72.70000000000014])\n",
      "\n",
      "\n",
      "IERKKWPIGKVCRNRYGRKIRR\n",
      "-0.7141862\n",
      "IERKKWPIGKVCRNRYGRKIRR\n",
      "   ||||||||\n",
      "KVVKQWPIGKVVKKVVKKVVK-\n",
      "  Score=53\n",
      "\n",
      "([0.3740757975896999, 0.32365788895088604, 0.18727272727272723], [74.60000000000004, 62.200000000000614, 43.40000000000035])\n",
      "\n",
      "\n",
      "TDWFVSILLNSNCQKHNTPLYGY\n",
      "-0.633139\n",
      "TDWFVSILLN--SNCQKHNTPLYGY--\n",
      "   |||||||||||\n",
      "---FLSTLLNVASNVVPTLICKITKKC\n",
      "  Score=37\n",
      "\n",
      "([0.06411761540563234, 0.0539340076091686, 0.12608695652173915], [12.79999999999997, 8.299999999999986, 53.60000000000049])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_indices=np.argpartition(pred_log_mics,4)[:4]\n",
    "print best_indices\n",
    "for index in best_indices:\n",
    "    seq=sequences[index]['sequence'][:sequences[index]['sequence'].find('_')]\n",
    "    print seq\n",
    "    print pred_log_mics[index]\n",
    "    show_best_n_alignments(seq,all_sequences,1)\n",
    "    print hmoment_analysis(seq)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_best_n_alignments(test_sequence,sequence_db,nalign,score_matrix=matlist.pam30,gap_open_penalty=-9,gap_extension_penalty=-1):\n",
    "#     blosum62 is another option. Identity matrix is another. I think they're about the same.\n",
    "    alignment_scores=[0]*len(sequence_db)\n",
    "    for i in range(len(all_sequences)):\n",
    "        sequence=all_sequences[i]\n",
    "        alignment_scores[i]=pairwise2.align.localds(test_sequence,sequence,score_matrix,gap_open_penalty,gap_extension_penalty,score_only=True)\n",
    "    argm = np.argmax(alignment_scores)\n",
    "#     alignments=pairwise2.align.localds(test_sequence,all_sequences[argm],score_matrix,gap_open_penalty,gap_extension_penalty)\n",
    "    indices=np.argpartition(alignment_scores,-1*nalign)[(-1*nalign):]\n",
    "    for index in indices:\n",
    "        alignments=pairwise2.align.localds(test_sequence,all_sequences[index],score_matrix,gap_open_penalty,gap_extension_penalty)\n",
    "        print(pairwise2.format_alignment(*alignments[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRRWKLMKHVTETPNPR\n",
      "||||||||||\n",
      "GKWWSLLKHILK-----\n",
      "  Score=39\n",
      "\n",
      "GRRWKLMKHVTETPNPR-----\n",
      "   |||||||\n",
      "--KWKLKKHIGIGKHFLSAKKF\n",
      "  Score=43\n",
      "\n",
      "GRRW-KLMKHVTETPNPR\n",
      " |||||||\n",
      "RRRWWKLMM---------\n",
      "  Score=45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_sequences=[sequence for sequence in ecoli_df.sequence]\n",
    "show_best_n_alignments('GRRWKLMKHVTETPNPR',all_sequences,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hmoment_analysis(test_sequence,angles=[100,140,180]):\n",
    "    hmoments=[0]*len(angles)\n",
    "    percentiles=[0]*len(angles)\n",
    "    for k in range(len(angles)):\n",
    "        test_angle=angles[k]\n",
    "        hmoments[k] = hydrophobic_moment(test_sequence,angle=test_angle)\n",
    "        other_h_moments=[0]*1000\n",
    "        shuffled=range(len(test_sequence))\n",
    "        perGreater=0\n",
    "        for i in range(1000):\n",
    "            np.random.shuffle(shuffled)\n",
    "            shuffled_seq=[test_sequence[j] for j in shuffled]\n",
    "            other_h_moments[i]=hydrophobic_moment(shuffled_seq,angle=test_angle)\n",
    "            if other_h_moments[i]<hydrophobic_moment(test_sequence,angle=test_angle):\n",
    "                perGreater+=.1\n",
    "        percentiles[k]=perGreater\n",
    "    return hmoments,percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.28744000139810794, 0.23115044867895798, 0.19357142857142856], [76.69999999999992, 59.70000000000058, 59.20000000000057])\n"
     ]
    }
   ],
   "source": [
    "print hmoment_analysis(u'YLFGLRVGKCWERNKALIAGTVLRISFH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1.])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
